<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 能工巧匠集 | OneV's Den]]></title>
  <link href="http://onevcat.com/category/neng-gong-qiao-jiang-ji/atom.xml" rel="self"/>
  <link href="http://onevcat.com/"/>
  <updated>2013-09-19T00:13:28+09:00</updated>
  <id>http://onevcat.com/</id>
  <author>
    <name><![CDATA[onevcat]]></name>
    <email><![CDATA[onev@onevcat.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[WWDC 2013 Session笔记 - iOS7中弹簧式列表的制作]]></title>
    <link href="http://onevcat.com/2013/09/spring-list-like-ios7-message/"/>
    <updated>2013-09-01T23:03:00+09:00</updated>
    <id>http://onevcat.com/2013/09/spring-list-like-ios7-message</id>
    <content type="html"><![CDATA[<p>这是我的WWDC2013系列笔记中的一篇，完整的笔记列表请参看<a href="http://onevcat.com/2013/06/developer-should-know-about-ios7/">这篇总览</a>。本文仅作为个人记录使用，也欢迎在<a href="http://creativecommons.org/licenses/by-nc/3.0/deed.zh">许可协议</a>范围内转载或使用，但是还烦请保留原文链接，谢谢您的理解合作。如果您觉得本站对您能有帮助，您可以使用<a href="http://onevcat.com/atom.xml">RSS</a>或<a href="http://eepurl.com/wNSkj">邮件</a>方式订阅本站，这样您将能在第一时间获取本站信息。</p>

<p>本文涉及到的WWDC2013 Session有</p>

<ul>
<li>Session 206 Getting Started with UIKit Dynamics</li>
<li>Session 217 Exploring Scroll Views in iOS7</li>
</ul>


<p>UIScrollView可以说是UIKit中最重要的类之一了，包括UITableView和UICollectionView等重要的数据容器类都是UIScrollView的子类。在历年的WWDC上，UIScrollView和相关的API都有专门的主题进行介绍，也可以看出这个类的使用和变化之快。今年也不例外，因为iOS7完全重新定义了UI，这使得UIScrollView里原来不太会使用的一些用法和实现的效果在新的系统中得到了很好的表现。另外，由于引入了UIKit Dynamics，我们还可以结合ScrollView做出一些以前不太可能或者需要花费很大力气来实现的效果，包括带有重力的swipe或者是类似新的信息app中的带有弹簧效果聊天泡泡等。如果您还不太了解iOS7中信息app的效果，这里有一张gif图可以帮您大概了解一下：</p>

<p><img src="http://img.onevcat.com/2013/ios7-message-app-spring.gif" alt="iOS7中信息app的弹簧效果" /></p>

<p>这次笔记的内容主要就是实现一个这样的效果。为了避免重复造轮子，我对这个效果进行了一些简单的封装，并连同这篇笔记的demo一起扔在了Github上，有需要的童鞋可以<a href="https://github.com/onevcat/VVSpringCollectionViewFlowLayout">到这里</a>自取。</p>

<p>iOS7的SDK中Apple最大的野心其实是想用SpriteKit来结束iOS平台游戏开发（至少是2D游戏开发）的乱战，统一游戏开发的方式并建立良性社区。而UIKit Dynamics，个人猜测Apple在花费力气为SpriteKit开发了物理引擎的同时，发现在UIKit中也可以使用，并能得到不错的效果，于是顺便革新了一下设计理念，在UI设计中引入了不少物理的概念。在iOS系统中，最为典型的应用是锁屏界面打开相机时中途放弃后的重力下坠+反弹的效果，另一个就是信息应用中的加入弹性的消息列表了。弹性列表在我自己上手试过以后觉得表现形式确实很生动，可以消除原来列表那种冷冰冰的感觉，是有可能在今后的设计中被大量使用的，因此决定学上一学。</p>

<p>首先我们需要知道要如何实现这样一种效果，我们会用到哪些东西。毋庸置疑，如果不使用UIKit Dynamics的话，自己从头开始来完成会是一件非常费力的事情，你可能需要实现一套位置计算和物理模拟来使效果看起来真实滑润。而UIKit Dynamics中已经给我们提供了现成的弹簧效果，可以用<code>UIAttachmentBehavior</code>进行实现。另外，在说到弹性效果的时候，我们其实是在描述一个列表中的各个cell之间的关系，对于传统的UITableView来说，描述UITableViewCell之间的关系是比较复杂的（因为Apple已经把绝大多数工作做了，包括计算cell位置和位移等。使用越简单，定制就会越麻烦在绝大多数情况下都是真理）。而UICollectionView则通过layout来完成cell之间位置关系的描述，给了开发者较大的空间来实现布局。另外，UIKit Dynamics为UICollectionView做了很多方便的Catagory，可以很容易地“指导”UICollectionView利用加入物理特性计算后的结果，在实现弹性效果的时候，UICollectionView是我们不二的选择。</p>

<p>如果您在阅读这篇笔记的时候遇到困难的话，建议您可以看看我之前的一些笔记，包括今年的<a href="http://onevcat.com/2013/06/uikit-dynamics-started/">UIKit Dynamics的介绍</a>和去年的<a href="http://onevcat.com/2012/06/introducing-collection-views/">UICollectionView介绍</a>。</p>

<!--more-->


<p>话不多说，我们开工。首先准备一个UICollectionViewFlowLayout的子类（在这里叫做<code>VVSpringCollectionViewFlowLayout</code>），然后在ViewController中用这个layout实现一个简单的collectionView：</p>

<p>```objc
//ViewController.m</p>

<p>@interface ViewController ()&lt;UICollectionViewDataSource, UICollectionViewDelegate>
@property (nonatomic, strong) VVSpringCollectionViewFlowLayout *layout;
@end</p>

<p>static NSString *reuseId = @"collectionViewCellReuseId";</p>

<p>@implementation ViewController
- (void)viewDidLoad
{</p>

<pre><code>[super viewDidLoad];
// Do any additional setup after loading the view, typically from a nib.

self.layout = [[VVSpringCollectionViewFlowLayout alloc] init];
self.layout.itemSize = CGSizeMake(self.view.frame.size.width, 44);
UICollectionView *collectionView = [[UICollectionView alloc] initWithFrame:self.view.frame collectionViewLayout:self.layout];

collectionView.backgroundColor = [UIColor clearColor];

[collectionView registerClass:[UICollectionViewCell class] forCellWithReuseIdentifier:reuseId];

collectionView.dataSource = self;
[self.view insertSubview:collectionView atIndex:0];
</code></pre>

<p>}</p>

<h1>pragma mark - UICollectionViewDataSource</h1>

<ul>
<li><p>(NSInteger)collectionView:(UICollectionView *)collectionView numberOfItemsInSection:(NSInteger)section
{
  return 50;
}</p></li>
<li><p>(UICollectionViewCell <em>)collectionView:(UICollectionView </em>)collectionView cellForItemAtIndexPath:(NSIndexPath <em>)indexPath
{
  UICollectionViewCell </em>cell = [collectionView dequeueReusableCellWithReuseIdentifier:reuseId forIndexPath:indexPath];</p>

<p>  //Just give a random color to the cell. See https://gist.github.com/kylefox/1689973
  cell.contentView.backgroundColor = [UIColor randomColor];
  return cell;
}
@end
```</p></li>
</ul>


<p>这部分没什么可以多说的，现在我们有一个标准的FlowLayout的UICollectionView了。通过使用UICollectionViewFlowLayout的子类来作为开始的layout，我们可以节省下所有的初始cell位置计算的代码，在上面代码的情况下，这个collectionView的表现和一个普通的tableView并没有太大不同。接下来我们着重来看看要如何实现弹性的layout。对于弹性效果，我们需要的是连接一个item和一个锚点间弹性连接的<code>UIAttachmentBehavior</code>，并能在滚动时设置新的锚点位置。我们在scroll的时候，只要使用UIKit Dynamics的计算结果，替代掉原来的位置更新计算（其实就是简单的scrollView的contentOffset的改变），就可以模拟出弹性的效果了。</p>

<p>首先在<code>-prepareLayout</code>中为cell添加<code>UIAttachmentBehavior</code>。</p>

<p>```objc
//VVSpringCollectionViewFlowLayout.m
@interface VVSpringCollectionViewFlowLayout()
@property (nonatomic, strong) UIDynamicAnimator *animator;
@end</p>

<p>@implementation VVSpringCollectionViewFlowLayout
//...</p>

<p>-(void)prepareLayout {</p>

<pre><code>[super prepareLayout];

if (!_animator) {
    _animator = [[UIDynamicAnimator alloc] initWithCollectionViewLayout:self];
    CGSize contentSize = [self collectionViewContentSize];
    NSArray *items = [super layoutAttributesForElementsInRect:CGRectMake(0, 0, contentSize.width, contentSize.height)];

    for (UICollectionViewLayoutAttributes *item in items) {
        UIAttachmentBehavior *spring = [[UIAttachmentBehavior alloc] initWithItem:item attachedToAnchor:item.center];

        spring.length = 0;
        spring.damping = 0.5;
        spring.frequency = 0.8;

        [_animator addBehavior:spring];
    }
}
</code></pre>

<p>}
@end
```</p>

<p>prepareLayout将在CollectionView进行排版的时候被调用。首先当然是call一下super的prepareLayout，你肯定不会想要全都要自己进行设置的。接下来，如果是第一次调用这个方法的话，先初始化一个UIDynamicAnimator实例，来负责之后的动画效果。iOS7 SDK中，UIDynamicAnimator类专门有一个针对UICollectionView的Category，以使UICollectionView能够轻易地利用UIKit Dynamics的结果。在<code>UIDynamicAnimator.h</code>中能够找到这个Category：</p>

<p>```objc
@interface UIDynamicAnimator (UICollectionViewAdditions)</p>

<p>// When you initialize a dynamic animator with this method, you should only associate collection view layout attributes with your behaviors.
// The animator will employ thecollection view layout’s content size coordinate system.
- (instancetype)initWithCollectionViewLayout:(UICollectionViewLayout*)layout;</p>

<p>// The three convenience methods returning layout attributes (if associated to behaviors in the animator) if the animator was configured with collection view layout
- (UICollectionViewLayoutAttributes<em>)layoutAttributesForCellAtIndexPath:(NSIndexPath</em>)indexPath;
- (UICollectionViewLayoutAttributes<em>)layoutAttributesForSupplementaryViewOfKind:(NSString </em>)kind atIndexPath:(NSIndexPath <em>)indexPath;
- (UICollectionViewLayoutAttributes</em>)layoutAttributesForDecorationViewOfKind:(NSString<em>)decorationViewKind atIndexPath:(NSIndexPath </em>)indexPath;</p>

<p>@end
```</p>

<p>于是通过<code>-initWithCollectionViewLayout:</code>进行初始化后，这个UIDynamicAnimator实例便和我们的layout进行了绑定，之后这个layout对应的attributes都应该由绑定的UIDynamicAnimator的实例给出。就像下面这样：</p>

<p>```objc
//VVSpringCollectionViewFlowLayout.m
@implementation VVSpringCollectionViewFlowLayout</p>

<p>//...</p>

<p>-(NSArray *)layoutAttributesForElementsInRect:(CGRect)rect {</p>

<pre><code>return [_animator itemsInRect:rect];
</code></pre>

<p>}</p>

<p>-(UICollectionViewLayoutAttributes <em>)layoutAttributesForItemAtIndexPath:(NSIndexPath </em>)indexPath {</p>

<pre><code>return [_animator layoutAttributesForCellAtIndexPath:indexPath];
</code></pre>

<p>}
@end
```</p>

<p>让我们回到<code>-prepareLayout</code>方法中，在创建了UIDynamicAnimator实例后，我们对于这个layout中的每个attributes对应的点，都创建并添加一个添加一个<code>UIAttachmentBehavior</code>（在iOS7 SDK中，UICollectionViewLayoutAttributes已经实现了UIDynamicItem接口，可以直接参与UIKit Dynamic的计算中去）。创建时我们希望collectionView的每个cell就保持在原位，因此我们设定了锚点为当前attribute本身的center。</p>

<p>接下来我们考虑滑动时的弹性效果的实现。在系统的信息app中，我们可以看到弹性效果有两个特点：</p>

<ul>
<li>随着滑动的速度增大，初始的拉伸和压缩的幅度将变大</li>
<li>随着cell距离屏幕触摸位置越远，拉伸和压缩的幅度</li>
</ul>


<p>对于考虑到这两方面的特点，我们所期望的滑动时的各cell锚点的变化应该是类似这样的：</p>

<p><img src="http://img.onevcat.com/2013/spring-list-ios7.png" alt="向上拖动时的锚点变化示意" /></p>

<p>现在我们来实现这个锚点的变化。既然都是滑动，我们是不是可以考虑在UIScrollView的<code>–scrollViewDidScroll:</code>委托方法中来设定新的Behavior锚点值呢？理论上来说当然是可以的，但是如果这样的话我们大概就不得不面临着将刚才的layout实例设置为collectionView的delegate这样一个事实。但是我们都知道layout应该做的事情是给collectionView提供必要的布局信息，而不应该负责去处理它的委托事件。处理collectionView的回调更恰当地应该由处于collectionView的controller层级的类来完成，而不应该由一个给collectionView提供数据和信息的类来响应。在<code>UICollectionViewLayout</code>中，我们有一个叫做<code>-shouldInvalidateLayoutForBoundsChange:</code>的方法，每次layout的bounds发生变化的时候，collectionView都会询问这个方法是否需要为这个新的边界和更新layout。一般情况下只要layout没有根据边界不同而发生变化的话，这个方法直接不做处理地返回NO，表示保持现在的layout即可，而每次bounds改变时这个方法都会被调用的特点正好可以满足我们更新锚点的需求，因此我们可以在这里面完成锚点的更新。</p>

<p>```objc
//VVSpringCollectionViewFlowLayout.m
@implementation VVSpringCollectionViewFlowLayout</p>

<p>//...</p>

<p>-(BOOL)shouldInvalidateLayoutForBoundsChange:(CGRect)newBounds {</p>

<pre><code>UIScrollView *scrollView = self.collectionView;
CGFloat scrollDelta = newBounds.origin.y - scrollView.bounds.origin.y;

//Get the touch point
CGPoint touchLocation = [scrollView.panGestureRecognizer locationInView:scrollView];

for (UIAttachmentBehavior *spring in _animator.behaviors) {
    CGPoint anchorPoint = spring.anchorPoint;

    CGFloat distanceFromTouch = fabsf(touchLocation.y - anchorPoint.y);
    CGFloat scrollResistance = distanceFromTouch / 500;

    UICollectionViewLayoutAttributes *item = [spring.items firstObject];
    CGPoint center = item.center;

    //In case the added value bigger than the scrollDelta, which leads an unreasonable effect
    center.y += (scrollDelta &gt; 0) ? MIN(scrollDelta, scrollDelta * scrollResistance)
                                  : MAX(scrollDelta, scrollDelta * scrollResistance);
    item.center = center;

    [_animator updateItemUsingCurrentState:item];
}
return NO;
</code></pre>

<p>}</p>

<p>@end
```</p>

<p>首先我们计算了这次scroll的距离<code>scrollDelta</code>，为了得到每个item与触摸点的之间的距离，我们当然还需要知道触摸点的坐标<code>touchLocation</code>。接下来，可以根据距离对每个锚点进行设置了：简单地计算了原来锚点与触摸点之间的距离<code>distanceFromTouch</code>，并由此计算一个系数。接下来，对于当前的item，我们获取其当前锚点位置，然后将其根据<code>scrollDelta</code>的数值和刚才计算的系数，重新设定锚点的位置。最后我们需要告诉UIDynamicAnimator我们已经完成了对冒点的更新，现在可以开始更新物理计算，并随时准备collectionView来取LayoutAttributes的数据了。</p>

<p>也许你还没有缓过神来？但是我们确实已经做完了，让我们来看看实际的效果吧：</p>

<p><img src="http://img.onevcat.com/2013/spring-collection-view-over-ios7.gif" alt="带有弹性效果的collecitonView" /></p>

<p>当然，通过调节<code>damping</code>，<code>frequency</code>和scrollResistance的系数等参数，可以得到弹性不同的效果，比如更多的震荡或者更大的幅度等等。</p>

<p>这个layout实现起来非常简单，我顺便封装了一下放到了Github上，大家有需要的话可以<a href="https://github.com/onevcat/VVSpringCollectionViewFlowLayout">点击这里下载</a>并直接使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[猫都能学会的Unity3D Shader入门指南（二）]]></title>
    <link href="http://onevcat.com/2013/08/shader-tutorial-2/"/>
    <updated>2013-08-31T22:18:00+09:00</updated>
    <id>http://onevcat.com/2013/08/shader-tutorial-2</id>
    <content type="html"><![CDATA[<p><img src="http://img.onevcat.com/2013/shader-tutorial2-light.jpg" alt="Unity Shader教程" /></p>

<h2>关于本系列</h2>

<p>这是Unity3D Shader入门指南系列的第二篇，本系列面向的对象是新接触Shader开发的Unity3D使用者，因为我本身自己也是Shader初学者，因此可能会存在错误或者疏漏，如果您在Shader开发上有所心得，很欢迎并恳请您指出文中纰漏，我会尽快改正。在<a href="http://onevcat.com/2013/07/shader-tutorial-1/">之前的开篇</a>中介绍了一些Shader的基本知识，包括ShaderLab的基本结构和语法，以及简单逐句地讲解了一个基本的shader。在具有这些基础知识后，阅读简单的shader应该不会有太大问题，在继续教程之前简单阅读一下Unity的<a href="http://docs.unity3d.com/Documentation/Components/SL-SurfaceShaderExamples.html">Surface Shader Example</a>，以检验您是否掌握了上一节的内容。如果您对阅读大部分示例Shader并没有太大问题，可以正确地指出Shader的结构，声明和使用的话，就说明您已经准备好继续阅读本节的内容了。</p>

<h2>法线贴图(Normal Mapping)</h2>

<p>法线贴图是凸凹贴图(Bump mapping)的一种常见应用，简单说就是在不增加模型多边形数量的前提下，通过渲染暗部和亮部的不同颜色深度，来为原来的贴图和模型增加视觉细节和真实效果。简单原理是在普通的贴图的基础上，再另外提供一张对应原来贴图的，可以表示渲染浓淡的贴图。通过将这张附加的表示表面凸凹的贴图的因素于实际的原贴图进行运算后，可以得到新的细节更加丰富富有立体感的渲染效果。在本节中，我们将首先实现一个法线贴图的Shader，然后对Unity Shader的光照模型进行一些讨论，并实现一个自定义的光照模型。最后再通过更改shader模拟一个石头上的积雪效果，并对模型顶点进行一些修改使积雪效果看起来比较真实。在本节结束的时候，我们就会有一个比较强大的可以满足一些真实开发工作时可用的shader了，而且更重要的是，我们将会掌握它是如何被创造出来的。</p>

<!--more-->


<p>关于法线贴图的效果图，可以对比看看下面。模型面数为500，左侧只使用了简单的Diffuse着色，右侧使用了法线贴图。比较两张图片不难发现，使用了法线贴图的石头在暗部和亮部都有着更好的表现。整体来说，凸凹感比Diffuse的结果增强许多，石头看起来更真实也更具有质感。</p>

<p><img src="http://img.onevcat.com/2013/shader-tutorial2-compare.jpg" alt="image" /></p>

<p>本节中需要用到的上面的素材可以<a href="http://vdisk.weibo.com/s/y-NNpUsxhYhZI">在这里下载</a>，其中包括上面的石块的模型，一张贴图以及对应的法线贴图。将下载的package导入到工程中，并新建一个material，使用简单的Diffuse的Shader（比如上一节我们实现的），再加上一个合适的平行光光源，就可以得到我们左图的效果。另外，本节以及以后都会涉及到一些Unity内建的Shader的内容，比如一些标准常用函数和常量定义等，相关内容可以在Unity的内建Shader中找到，内建Shader可以在<a href="http://unity3d.com/unity/download/archive">Unity下载页面</a>的版本右侧找到。</p>

<p>接下来我们实现法线贴图。在实现之前，我们先简单地稍微多了解一些法线贴图的基本知识。大多数法线图一般都和下面的图类似，是一张以蓝紫色为主的图。这张法线图其实是一张RGB贴图，其中红，绿，蓝三个通道分别表示由高度图转换而来的该点的法线指向：Nx、Ny、Nz。在其中绝大部分点的法线都指向z方向，因此图更偏向于蓝色。在shader进行处理时，我们将光照与该点的法线值进行点积后即可得到在该光线下应有的明暗特性，再将其应用到原图上，即可反应在一定光照环境下物体的凹凸关系了。关于法向贴图的更多信息，可以参考<a href="http://en.wikipedia.org/wiki/Normal_mapping">wiki上的相关条目</a>。</p>

<p><img src="http://img.onevcat.com/2013/shader-tutorial2-normal.jpg" alt="一张典型的法线图" /></p>

<p>回到正题，我们现在考虑的主要是Shader入门，而不是图像学的原理。再上一节我们写的Shader的基础上稍微做一些修改，就可以得到适应并完成法线贴图渲染的新Shader。新加入的部分进行了编号并在之后进行说明。</p>

<p>```glsl
Shader "Custom/Normal Mapping" {</p>

<pre><code>Properties {
    _MainTex ("Base (RGB)", 2D) = "white" {}

    //1
    _Bump ("Bump", 2D) = "bump" {}
}
SubShader {
    Tags { "RenderType"="Opaque" }
    LOD 200

    CGPROGRAM
    #pragma surface surf Lambert

    sampler2D _MainTex;

    //2
    sampler2D _Bump;                

    struct Input {
        float2 uv_MainTex;

        //3
        float2 uv_Bump;
    };

    void surf (Input IN, inout SurfaceOutput o) {
        half4 c = tex2D (_MainTex, IN.uv_MainTex);

        //4
        o.Normal = UnpackNormal(tex2D(_Bump, IN.uv_Bump);

        o.Albedo = c.rgb;
        o.Alpha = c.a;
    }
    ENDCG
} 
FallBack "Diffuse"
</code></pre>

<p>}
```</p>

<ol>
<li>声明并加入一个显示名称为<code>Bump</code>的贴图，用于放置法线图</li>
<li>为了能够在CG程序中使用这张贴图，必须加入一个sample，希望你还记得～</li>
<li>获取Bump的uv信息作为输入</li>
<li>从法线图中提取法线信息，并将其赋予相应点的输出的Normal属性。<code>UnpackNormal</code>是定义在UnityCG.cginc文件中的方法，这个文件中包含了一系列常用的CG变量以及方法。<code>UnpackNormal</code>接受一个fixed4的输入，并将其转换为所对应的法线值（fixed3）。在解包得到这个值之后，将其赋给输出的Normal，就可以参与到光线运算中完成接下来的渲染工作了。</li>
</ol>


<p>现在保存并且编译这个Shader，创建新的material并使用这个shader，将石头的材质贴图和法线图分别拖放到Base和Bump里，再将其应用到石头模型上，应该就可以看到右侧图的效果了。</p>

<h2>光照模型</h2>

<p>在我们之前的看到的Shader中（其实也就上一节的基本diffuse和这里的normal mapping），都只使用了Lambert的光照模型（#pragma surface surf Lambert），这是一个很经典的漫反射模型，光强与入射光的方向和反射点处表面法向夹角的余弦成正比。关于Lambert和漫反射的一些详细的计算和推论，可以参看wiki（<a href="http://en.wikipedia.org/wiki/Lambertian_reflectance">Lambert</a>，<a href="http://en.wikipedia.org/wiki/Diffuse_reflection">漫反射</a>）或者其他地方的介绍。一句话的简单解释就是一个点的反射光强是和该点的法线向量和入射光向量和强度和夹角有关系的，其结果就是这两个向量的点积。既然已经知道了光照计算的原理，我们先来看看如何实现一个自己的光照模型吧。</p>

<p>在刚才的Shader上进行如下修改。</p>

<ul>
<li>首先将原来的<code>#pragma</code>行改为这样</li>
</ul>


<p>```glsl</p>

<h1>pragma surface surf CustomDiffuse</h1>

<p>```</p>

<ul>
<li>然后在SubShader块中添加如下代码</li>
</ul>


<p>```glsl
inline float4 LightingCustomDiffuse (SurfaceOutput s, fixed3 lightDir, fixed atten) {</p>

<pre><code>float difLight = max(0, dot (s.Normal, lightDir));
float4 col;
col.rgb = s.Albedo * _LightColor0.rgb * (difLight * atten * 2);
col.a = s.Alpha;
return col;
</code></pre>

<p>}
```</p>

<ul>
<li>最后保存，回到Unity。Shader将编译，如果一切正常，你将不会看到新的shader和之前的在材质表现上有任何不同。但是事实上我们现在的shader已经与Unity内建的diffuse光照模型撇清了关系，而在使用我们自己设定的光照模型了。</li>
</ul>


<p>喵的，这些代码都干了些什么！相信你一定会有这样的疑惑...没问题，没有疑惑的话那就不叫初学了，还是一行行讲来。首先正像我们上一篇所说，<code>#pragma</code>语句在这里声明了接下来的Shader的类型，计算调用的方法名，以及指定光照模型。在之前我们一直指定Lambert为光照模型，而现在我们将其换为了CustomDiffuse。</p>

<p>接下来添加的代码是计算光照的实现。shader中对于方法的名称有着比较严格的约定，想要创建一个光照模型，首先要做的是按照规则声明一个光照计算的函数名字，即<code>Lighting&lt;Your Chosen Name&gt;</code>。对于我们的光照模型CustomDiffuse，其计算函数的名称自然就是<code>LightingCustomDiffuse</code>了。光照模型的计算是在surf方法的表面颜色之后，根据输入的光照条件来对原来的颜色在这种光照下的表现进行计算，最后输出新的颜色值给渲染单元完成在屏幕的绘制。</p>

<p>也许你已经猜到了，我们之前用的Lambert光照模型是不是也有一个名字叫LightingLambert的光照计算函数呢？Bingo。在Unity的内建Shader中，有一个Lighting.cginc文件，里面就包含了LightingLambert的实现。也许你也注意到了，我们所实现的LightingCustomDiffuse的内容现在和Unity内建中的LightingLambert是完全一样的，这也就是使用新的shader的原来视觉上没有区别的原因，因为实现确实是完全一样的。</p>

<p>首先来看输入量，<code>SurfaceOutput s</code>这个就是经过表面计算函数surf处理后的输出，我们讲对其上的点根据光线进行处理，<code>fixed3 lightDir</code>是光线的方向，<code>fixed atten</code>表示光衰减的系数。在计算光照的代码中，我们先将输入的s的法线值（在Normal mapping中的话这个值已经是法线图中的对应量了）和输入光线进行点积（dot函数是CG中内置的数学函数，希望你还记得，可以<a href="http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter05.html">参考这里</a>）。点积的结果在-1至1之间，这个值越大表示法线与光线间夹角越小，这个点也就应该越亮。之后使用max来将这个系数结果限制在0到1之间，是为了避免负数情况的存在而导致最终计算的颜色变为负数，输出一团黑，一般来说这是我们不愿意看到的。接下来我们将surf输出的颜色与光线的颜色<code>_LightColor0.rgb</code>（由Unity根据场景中的光源得到的，它在Lighting.cginc中有声明）进行乘积，然后再与刚才计算的光强系数和输入的衰减系数相乘，最后得到在这个光线下的颜色输出（关于difLight * atten * 2中为什么有个乘2，这是一个历史遗留问题，主要是为了进行一些光强补偿，可以参见<a href="http://forum.unity3d.com/threads/94711-Why-(atten-*-2">这里的讨论</a>)）。</p>

<p>在了解了基本实现方式之后，我们可以看看做一些修改玩玩儿。最简单的比如将这个Lambert模型改亮一些，比如换成Half Lambert模型。Half Lambert是由Valve创造的可以使物体在低光线条件下增亮的技术，最早被用于半条命（Half Life）中以避免在低光下物体的走形。简单说就是把光强系数先取一半，然后在加0.5，代码如下：</p>

<p>```glsl
inline float4 LightingCustomDiffuse (SurfaceOutput s, fixed3 lightDir, fixed atten) {</p>

<pre><code>float difLight = dot (s.Normal, lightDir);
float hLambert = difLight * 0.5 + 0.5;
float4 col;
col.rgb = s.Albedo * _LightColor0.rgb * (hLambert * atten * 2);
col.a = s.Alpha;
return col;
</code></pre>

<p>}
```</p>

<p>这样一来，原来光强0的点，现在对应的值变为了0.5，而原来是1的地方现在将保持为1。也就是说模型贴图的暗部被增强变亮了，而亮部基本保持和原来一样，防止过曝。使用Half Lambert前后的效果图如下，注意最右侧石头下方的阴影处细节更加明显了，而这一切都只是视觉效果的改变，不涉及任何贴图和模型的变化。</p>

<p><img src="http://img.onevcat.com/2013/shader-toturial-hl.jpg" alt="Half Lambert下发现贴图的表现" /></p>

<h2>表面贴图的追加效果</h2>

<p>OK，对于光线和自定义光照模型的讨论暂时到此为止，因为如果展开的话这将会一个庞大的图形学和经典光学的话题了。我们回到Shader，并且一起实现一些激动人心的效果吧。比如，在你的游戏场景中有一幕是雪地场景，而你希望做一些石头上白雪皑皑的覆盖效果，应该怎么办呢？难道让你可爱的3D设计师再去出一套覆雪的贴图然后使用新的贴图？当然不，不是不能，而是不该。因为新的贴图不仅会增大项目的资源包体积，更会增大之后修改和维护的难度，想想要是有好多石头需要实现同样的覆雪效果，或者是要随着游戏时间堆积的雪逐渐变多的话，你应该怎么办？难道让设计师再把所有的石头贴图都盖上雪，然后再按照雪的厚度出5套不同的贴图么？相信我，他们会疯的。</p>

<p>于是，我们考虑用Shader来完成这件工作吧！先考虑下我们需要什么，积雪效果的话，我们需要积雪等级（用来表示积雪量），雪的颜色，以及积雪的方向。基本思路和实现自定义光照模型类似，通过计算原图的点在世界坐标中的法线方向与积雪方向的点积，如果大于设定的积雪等级的阈值的话则表示这个方向与积雪方向是一致的，其上是可以积雪的，显示雪的颜色，否则使用原贴图的颜色。废话不再多说，上代码，在上面的Shader的基础上，更改Properties里的内容为</p>

<p>```glsl
Properties {</p>

<pre><code>_MainTex ("Base (RGB)", 2D) = "white" {}
_Bump ("Bump", 2D) = "bump" {}
_Snow ("Snow Level", Range(0,1) ) = 0
_SnowColor ("Snow Color", Color) = (1.0,1.0,1.0,1.0)
_SnowDirection ("Snow Direction", Vector) = (0,1,0)
</code></pre>

<p>}
```</p>

<p>没有太多值得说的，唯一要提一下的是_SnowDirection设定的默认值为(0,1,0)，这表示我们希望雪是垂直落下的。对应地，在CG程序中对这些变量进行声明：</p>

<p><code>glsl
sampler2D _MainTex;
sampler2D _Bump;
float _Snow;
float4 _SnowColor;
float4 _SnowDirection;
</code></p>

<p>接下来改变Input的内容：</p>

<p>```glsl
struct Input {</p>

<pre><code>float2 uv_MainTex;
float2 uv_Bump;
float3 worldNormal; INTERNAL_DATA
</code></pre>

<p>};
```</p>

<p>相对于上面的Shader输入来说，加入了一个<code>float3 worldNormal; INTERNAL_DATA</code>，如果SurfaceOutput中设定了Normal值的话，通过worldNormal可以获取当前点在世界中的法线值。详细的解说可以参见<a href="http://docs.unity3d.com/Documentation/Components/SL-SurfaceShaders.html">Unity的Shader文档</a>。接下来可以改变surf函数，实装积雪效果了。</p>

<p>```glsl
void surf (Input IN, inout SurfaceOutput o) {</p>

<pre><code>half4 c = tex2D (_MainTex, IN.uv_MainTex);
o.Normal = UnpackNormal(tex2D(_Bump, IN.uv_Bump));

if (dot(WorldNormalVector(IN, o.Normal), _SnowDirection.xyz) &gt; lerp(1,-1,_Snow)) {
    o.Albedo = _SnowColor.rgb;
} else {
    o.Albedo = c.rgb;
}

o.Alpha = c.a;
</code></pre>

<p>}
```</p>

<p>和上面相比，加入了一个if…else…的判断。首先看这个条件的不等式的左侧，我们对雪的方向和和输入点的世界法线方向进行点积。<code>WorldNormalVector</code>通过输入的点及这个点的法线值，来计算它在世界坐标中的方向；右侧的lerp函数相信只要对插值有概念的同学都不难理解：当<em>Snow取最小值1时，这个函数将返回1，而</em>Snow取最大值时，返回-1。这样我们就可以通过设定<em>Snow的值来控制积雪的阈值，要是积雪等级</em>Snow是0时，不等式左侧不可能大于右侧，因此完全没有积雪；相反要是_Snow取最大值1时，由于左侧必定大于-1，所以全模型积雪。而随着取中间值的变化，积雪的情况便会有所不同。</p>

<p>应用这个Shader，并且适当地调节一下积雪等级和颜色，可以得到如下右边的效果。</p>

<p><img src="http://img.onevcat.com/2013/shader-tutorial2-snow.jpg" alt="添加了积雪效果的Shader" /></p>

<h2>更改顶点模型</h2>

<p>到现在位置，我们还仅指是在原贴图上进行操作，不管是用法线图使模型看起来凸凹有致，还是加上积雪，所有的计算和颜色的输出都只是“障眼法”，并没有对模型有任何实质的改动。但是对于积雪效果来说，实际上积雪是附加到石头上面，而不应当简单替换掉原来的颜色。但是具体实施起来，最简单的办法还是直接替换颜色，但是我们可以稍微变更一下模型，使原来的模型在积雪的方向稍微变大一些，这样来达到一种雪是附加到石头上的效果。</p>

<p>我们继续修改之前的Shader，首先我们需要告诉surface shadow我们要改变模型的顶点。首先将#param行改为</p>

<p><code>#pragma surface surf CustomDiffuse vertex:vert</code></p>

<p>这告诉Shader我们想要改变模型顶点，并且我们会写一个叫做<code>vert</code>的函数来改变顶点。接下来我们再添加一个参数，在Properties中声明一个<code>_SnowDepth</code>变量，表示积雪的厚度，当然我们也需要在CG段中进行声明：</p>

<p>```glsl
//In Properties{…}
_SnowDepth ("Snow Depth", Range(0,0.3)) = 0.1</p>

<p>//In CG declare
float _SnowDepth;
```</p>

<p>接下来实现vert方法，和之前积雪的运算其实比较类似，判断点积大小来决定是否需要扩大模型以及确定模型扩大的方向。在CG段中加入以下vert方法</p>

<p>```glsl
void vert (inout appdata_full v) {</p>

<pre><code>float4 sn = mul(transpose(_Object2World) , _SnowDirection);
if(dot(v.normal, sn.xyz) &gt;= lerp(1,-1, (_Snow * 2) / 3)) {
    v.vertex.xyz += (sn.xyz + v.normal) * _SnowDepth * _Snow;
}
</code></pre>

<p>}
```</p>

<p>和surf的原理差不多，系统会输入一个当前的顶点的值，我们根据需要计算并填上新的值作为返回即可。上面第一行中使用<code>transpose</code>方法输出原矩阵的转置矩阵，在这里_Object2World是Unity ShaderLab的内建值，它表示将当前模型转换到世界坐标中的矩阵，将其与积雪方向做矩阵乘积得到积雪方向在物体的世界空间中的投影（把积雪方向转换到世界坐标中）。之后我们计算了这个世界坐标中实际的积雪方向和当前点的法线值的点积，并将结果与使用积雪等级的2/3进行比较lerp后的阈值比较。这样，当前点如果和积雪方向一致，并且积雪较为完整的话，将改变该点的模型顶点高度。</p>

<p>加入模型更改前后的效果对比如下图，加入模型调整的右图表现要更为丰满真实。</p>

<p><img src="http://img.onevcat.com/2013/shader-tutorial2-snow-vert.jpg" alt="image" /></p>

<p>这节就到这里吧。本节中实现的Shader可以<a href="https://gist.github.com/onevcat/6396814">在这里找到完整版本</a>进行参考，希望大家周末愉快～</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WWDC 2013 Session笔记 - iOS7中的多任务]]></title>
    <link href="http://onevcat.com/2013/08/ios7-background-multitask/"/>
    <updated>2013-08-17T19:16:00+09:00</updated>
    <id>http://onevcat.com/2013/08/ios7-background-multitask</id>
    <content type="html"><![CDATA[<p><img src="http://img.onevcat.com/2013/ios7-multitasking.jpg" alt="iOS7的后台多任务特性" /></p>

<p>这是我的WWDC2013系列笔记中的一篇，完整的笔记列表请参看<a href="http://onevcat.com/2013/06/developer-should-know-about-ios7/">这篇总览</a>。本文仅作为个人记录使用，也欢迎在<a href="http://creativecommons.org/licenses/by-nc/3.0/deed.zh">许可协议</a>范围内转载或使用，但是还烦请保留原文链接，谢谢您的理解合作。如果您觉得本站对您能有帮助，您可以使用<a href="http://onevcat.com/atom.xml">RSS</a>或<a href="http://eepurl.com/wNSkj">邮件</a>方式订阅本站，这样您将能在第一时间获取本站信息。</p>

<p>本文涉及到的WWDC2013 Session有</p>

<ul>
<li>Session 204 What's New with Multitasking</li>
<li>Session 705 What’s New in Foundation Networking</li>
</ul>


<h2>iOS7以前的Multitasking</h2>

<p>iOS的多任务是在iOS4的时候被引入的，在此之前iOS的app都是按下Home键就被干掉了。iOS4虽然引入了后台和多任务，但是实际上是伪多任务，一般的app后台并不能执行自己的代码，只有少数几类服务在通过注册后可以真正在后台运行，并且在提交到AppStore的时候也会被严格审核是否有越权行为，这种限制主要是出于对于设备的续航和安全两方面进行的考虑。之后经过iOS5和6的逐渐发展，后台能运行的服务的种类虽然出现了增加，但是iOS后台的本质并没有变化。在iOS7之前，系统所接受的应用多任务可以大致分为几种：</p>

<ul>
<li>后台完成某些花费时间的特定任务</li>
<li>后台播放音乐等</li>
<li>位置服务</li>
<li>IP电话（VoIP）</li>
<li>Newsstand</li>
</ul>


<p>在WWDC 2013的keynote上，iOS7的后台多任务改进被专门拿出来向开发者进行了介绍，到底iOS7里多任务方面有什么新的特性可以利用，如何使用呢？简单来说，iOS7在后台特性方面有很大改进，不仅改变了以往的一些后台任务处理方式，还加入了全新的后台模式，本文将针对iOS7中新的后台特性进行一些学习和记录。大体来说，iOS7后台的变化在于以下四点：</p>

<ul>
<li>改变了后台任务的运行方式</li>
<li>增加了后台获取（Background Fetch）</li>
<li>增加了推送唤醒（静默推送，Silent Remote Notifications）</li>
<li>增加了后台传输（￼Background Transfer Service）</li>
</ul>


<!--more-->


<h2>iOS7的多任务</h2>

<h3>后台任务</h3>

<p>首先看看后台任务的变化，先说这方面的改变，而不是直接介绍新的API，是因为这个改变很典型地代表了iOS7在后台任务管理和能耗控制上的大体思路。从上古时期开始（其实也就4.0），UIApplication提供了<code>-beginBackgroundTaskWithExpirationHandler:</code>方法来使app在被切到后台后仍然能保持运行一段时间，app可以用这个方法来确保一些很重很慢的工作可以在急不可耐的用户将你的应用扔到后台后还能完成，比如编码视频，上传下载某些重要文件或者是完成某些数据库操作等，虽然时间不长，但在大多数情况下勉强够用。如果你之前没有使用过这个API的话，它使用起来大概是长这个样子的：</p>

<p>```objc
- (void) doUpdate</p>

<pre><code>dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{

    [self beginBackgroundUpdateTask];

    NSURLResponse * response = nil;
    NSError  * error = nil;
    NSData * responseData = [NSURLConnection sendSynchronousRequest: request returningResponse: &amp;response error: &amp;error];

    // Do something with the result

    [self endBackgroundUpdateTask];
});
</code></pre>

<p>}</p>

<ul>
<li><p>(void) beginBackgroundUpdateTask
{
  self.backgroundUpdateTask = [[UIApplication sharedApplication] beginBackgroundTaskWithExpirationHandler:<sup>{</sup></p>

<pre><code>  [self endBackgroundUpdateTask];
</code></pre>

<p>  }];
}</p></li>
<li><p>(void) endBackgroundUpdateTask
{
  [[UIApplication sharedApplication] endBackgroundTask: self.backgroundUpdateTask];
  self.backgroundUpdateTask = UIBackgroundTaskInvalid;
} <br/>
```</p></li>
</ul>


<p>在<code>beginBackgroundTaskWithExpirationHandler:</code>里写一个超时处理（系统只给app分配了一定时间来进行后台任务，超时之前会调用这个block），然后进行开始进行后台任务处理，在任务结束或者过期的时候call一下<code>endBackgroundTask:</code>使之与begin方法配对（否则你的app在后台任务超时的时候会被杀掉）。同时，你可以使用UIApplication实例的backgroundTimeRemaining属性来获取剩余的后台执行时间。</p>

<p>具体的执行时间来说，在iOS6和之前的系统中，系统在用户退出应用后，如果应用正在执行后台任务的话，系统会保持活跃状态直到后台任务完成或者是超时以后，才会进入真正的低功耗休眠状态。</p>

<p><img src="http://img.onevcat.com/2013/ios-multitask-ios6.png" alt="iOS6之前的后台任务处理" /></p>

<p>而在iOS7中，后台任务的处理方式发生了改变。系统将在用户锁屏后尽快让设备进入休眠状态，以节省电力，这时后台任务是被暂停的。之后在设备在特定时间进行系统应用的操作被唤醒（比如检查邮件或者接到来电等）时，之前暂停的后台任务将一起进行。就是说，系统不会专门为第三方的应用保持设备处于活动状态。如下图示</p>

<p><img src="http://img.onevcat.com/2013/ios-multitask-ios7.png" alt="iOS7的后台任务处理" /></p>

<p>这个变化在不减少应用的后台任务时间长度的情况下，给设备带来了更多的休眠时间，从而延长了续航。对于开发者来说，这个改变更多的是系统层级的变化，对于非网络传输的任务来说，保持原来的用法即可，新系统将会按照新的唤醒方式进行处理；而对于原来在后台做网络传输的应用来说，苹果建议在iOS7中使用<code>NSURLSession</code>，创建后台的session并进行网络传输，这样可以很容易地利用更好的后台传输API，而不必受限于原来的时长，关于这个具体的我们一会儿再说。</p>

<h3>后台获取（Background Fetch）</h3>

<p>现在的应用无法在后台获取信息，比如社交类应用，用户一定需要在打开应用之后才能进行网络连接，获取新的消息条目，然后才能将新内容呈现给用户。说实话这个体验并不是很好，用户在打开应用后必定会有一段时间的等待，每次皆是如此。iOS7中新加入的后台获取就是用来解决这个不足的：后台获取干的事情就是在用户打开应用之前就使app有机会执行代码来获取数据，刷新UI。这样在用户打开应用的时候，最新的内容将已然呈现在用户眼前，而省去了所有的加载过程。想想看，没有加载的网络体验的世界，会是怎样一种感觉。这已经不是smooth，而是真的amazing了。</p>

<p>那具体应该怎么做呢？一步一步来：</p>

<h4>启用后台获取</h4>

<p>首先是修改应用的Info.plist，在<code>UIBackgroundModes</code>中加入fetch，即可告诉系统应用需要后台获取的权限。另外一种更简单的方式，得益于Xcode5的Capabilities特性（参见可以参见我之前的一篇<a href="http://onevcat.com/2013/06/new-in-xcode5-and-objc/">WWDC2013笔记 Xcode5和ObjC新特性</a>），现在甚至都不需要去手动修改Info.plist来进行添加了，打开Capabilities页面下的Background Modes选项，并勾选Background fetch选项即可（如下图）。</p>

<p><img src="http://img.onevcat.com/2013/ios7-multitask-background-fetch.png" alt="在Capabilities中开启Background Modes" /></p>

<p>笔者写这篇文章的时候iOS7还没有上市，也没有相关的审核资料，所以不知道如果只是在这里打开了fetch选项，但却没有实现的话，应用会不会无法通过审核。但是依照苹果一贯的做法来看，如果声明了需要某项后台权限，但是结果却没有相关实现的话，被拒掉的可能性还是比较大的。因此大家尽量不要拿上线产品进行实验，而应当是在demo项目里研究明白以后再到上线产品中进行实装。</p>

<h4>设定获取间隔</h4>

<p>对应用的UIApplication实例设置获取间隔，一般在应用启动的时候调用以下代码即可：</p>

<p><code>objc
[[UIApplication sharedApplication] setMinimumBackgroundFetchInterval:UIApplicationBackgroundFetchIntervalMinimum];
</code></p>

<p>如果不对最小后台获取间隔进行设定的话，系统将使用默认值<code>UIApplicationBackgroundFetchIntervalNever</code>，也就是永远不进行后台获取。当然，<code>-setMinimumBackgroundFetchInterval:</code>方法接受的是NSTimeInterval，因此你也可以手动指定一个以秒为单位的最小获取间隔。需要注意的是，我们都已经知道iOS是一个非常霸道为我独尊的系统，因此自然也不可能让一介区区第三方应用来控制系统行为。这里所指定的时间间隔只是代表了“在上一次获取或者关闭应用之后，在这一段时间内一定不会去做后台获取”，而真正具体到什么时候会进行后台获取，那<del>完全是要看系统娘的心情的</del>我们是无从得知的。系统将根据你的设定，选择比如接收邮件的时候顺便为你的应用获取一下，或者也有可能专门为你的应用唤醒一下设备。作为开发者，我们应该做的是为用户的电池考虑，尽可能地选择合适自己应用的后台获取间隔。设置为UIApplicationBackgroundFetchIntervalMinimum的话，系统会尽可能多尽可能快地为你的应用进行后台获取，但是比如对于一个天气应用，可能对实时的数据并不会那么关心，就完全不必设置为UIApplicationBackgroundFetchIntervalMinimum，也许1小时会是一个更好的选择。新的Mac OSX 10.9上已经出现了功耗监测，用于让用户确定什么应用是能耗大户，有理由相信同样的东西也可能出现在iOS上。如果不想让用户因为你的应用是耗电大户而怒删的话，从现在开始注意一下应用的能耗还是蛮有必要的（做绿色环保低碳的iOS app，从今天开始～）。</p>

<h4>实现后台获取代码并通知系统</h4>

<p>在完成了前两步后，只需要在AppDelegate里实现<code>-application:performFetchWithCompletionHandler:</code>就行了。系统将会在执行fetch的时候调用这个方法，然后开发者需要做的是在这个方法里完成获取的工作，然后刷新UI，并通知系统获取结束，以便系统尽快回到休眠状态。获取数据这是应用相关的内容，在此不做赘述，应用在前台能完成的工作在这里都能做，唯一的限制是系统不会给你很长时间来做fetch，一般会小于一分钟，而且fetch在绝大多数情况下将和别的应用共用网络连接。这些时间对于fetch一些简单数据来说是足够的了，比如微博的新条目（大图除外），接下来一小时的天气情况等。如果涉及到较大文件的传输的话，用后台获取的API就不合适了，而应该使用另一个新的文件传输的API，我们稍后再说。类似前面提到的后台任务完成时必须通知系统一样，在在获取完成后，也必须通知系统获取完成，方法是调用<code>-application:performFetchWithCompletionHandler:</code>的handler。这个CompletionHandler接收一个<code>UIBackgroundFetchResult</code>作为参数，可供选择的结果有<code>UIBackgroundFetchResultNewData</code>,<code>UIBackgroundFetchResultNoData</code>,<code>UIBackgroundFetchResultFailed</code>三种，分别表示获取到了新数据（此时系统将对现在的UI状态截图并更新App Switcher中你的应用的截屏），没有新数据，以及获取失败。写一个简单的例子吧：</p>

<p>```objc
//File: YourAppDelegate.m
-(void)application:(UIApplication *)application performFetchWithCompletionHandler:(void (<sup>)(UIBackgroundFetchResult))completionHandler</sup>
{</p>

<pre><code>UINavigationController *navigationController = (UINavigationController*)self.window.rootViewController;

id fetchViewController = navigationController.topViewController;
if ([fetchViewController respondsToSelector:@selector(fetchDataResult:)]) {
    [fetchViewController fetchDataResult:^(NSError *error, NSArray *results){
        if (!error) {
            if (results.count != 0) {
                //Update UI with results.
                //Tell system all done.
                completionHandler(UIBackgroundFetchResultNewData);
            } else {
                completionHandler(UIBackgroundFetchResultNoData);
            }
        } else {
            completionHandler(UIBackgroundFetchResultFailed);
        }
    }];
} else {
    completionHandler(UIBackgroundFetchResultFailed);
}
</code></pre>

<p>}
```</p>

<p>当然，实际情况中会比这要复杂得多，用户当前的ViewController是否合适做获取，获取后的数据如何处理都需要考虑。另外要说明的是上面的代码在获取成功后直接在appDelegate里更新UI，这只是为了能在同一处进行说明，但却是不正确的结构。比较好的做法是将获取和更新UI的业务逻辑都放到fetchViewController里，然后向其发送获取消息的时候将completionHandler作为参数传入，并在fetchViewController里完成获取结束的报告。</p>

<p>另一个比较神奇的地方是系统将追踪用户的使用习惯，并根据对每个应用的使用时刻给一个合理的fetch时间。比如系统将记录你在每天早上9点上班的电车上，中午12点半吃饭时，以及22点睡觉前会刷一下微博，只要这个习惯持续个三四天，系统便会将应用的后台获取时刻调节为9点，12点和22点前一点。这样在每次你打开应用都直接有最新内容的同时，也节省了电量和流量。</p>

<h4>后台获取的调试</h4>

<p>既然是系统决定的fetch，那我们要如何测试写的代码呢？难道是将应用退到后台，然后安心等待系统进行后台获取么？当然不是...Xcode5为我们提供了两种方法来测试后台获取的代码。一种是从后台获取中启动应用，另一种是当应用在后台时模拟一次后台推送。</p>

<p>对于前者，我们可以新建一个Scheme来专门调试从后台启动。点击Xcode5的Product->Scheme->Edit Scheme(或者直接使用快捷键<code>⌘&lt;</code>)。在编辑Scheme的窗口中点Duplicate Scheme按钮复制一个当前方案，然后在新Scheme的option中将Background Fetch打上勾。从这个Scheme来运行应用的时候，应用将不会直接启动切入前台，而是调用后台获取部分代码并更新UI，这样再点击图标进入应用时，你应该可以看到最新的数据和更新好的UI了。</p>

<p><img src="http://img.onevcat.com/2013/ios7-back-fetch-scheme.png" alt="更改Scheme的选项为从后台获取事件中启动" /></p>

<p>另一种是当应用在后台时，模拟一次后台获取。这个比较简单，在app调试运行时，点击Xcode5的Debug菜单中的Simulate Background Fetch，即可模拟完成一次获取调用。</p>

<h3>推送唤醒（Remote Notifications）</h3>

<p>远程推送（￼￼Remote Push Notifications）可以说是增加用户留存率的不二法则，在iOS6和之前，推送的类型是很单一的，无非就是显示标题内容，指定声音等。用户通过解锁进入你的应用后，appDelegate中通过推送打开应用的回调将被调用，然后你再获取数据，进行显示。这和没有后台获取时的打开应用后再获取数据刷新的问题是一样的。在iOS7中这个行为发生了一些改变，我们有机会使设备在接收到远端推送后让系统唤醒设备和我们的后台应用，并先执行一段代码来准备数据和UI，然后再提示用户有推送。这时用户如果解锁设备进入应用后将不会再有任何加载过程，新的内容将直接得到呈现。</p>

<p>实装的方法和刚才的后台获取比较类似，还是一步步来：</p>

<h4>启用推送唤醒</h4>

<p>和上面的后台获取类似，更改Info.plist，在<code>UIBackgroundModes</code>下加入<code>remote-notification</code>即可开启，当然同样的更简单直接的办法是使用Capabilities。</p>

<h4>更改推送的payload</h4>

<p>在iOS7中，如果想要使用推送来唤醒应用运行代码的话，需要在payload中加入<code>content-available</code>，并设置为1。</p>

<p><code>javascript
aps {     content-available: 1     alert: {...}   }
</code>￼￼</p>

<h4>实现推送唤醒代码并通知系统</h4>

<p>最后在appDelegate中实现<code>￼-application:didReceiveRemoteNotification:fetchCompletionHandle:</code>。这部分内容和上面的后台获取部分完全一样，在此不再重复。</p>

<h4>一些限制和应用的例子</h4>

<p>因为一旦推送成功，用户的设备将被唤醒，因此这类推送不可能不受到限制。Apple将限制此类推送的频率，当频率超过一定限制后，带有content-available标志的推送将会被阻塞，以保证用户设备不被频繁唤醒。按照Apple的说法，这个频率在一小时内个位数次的推送的话不会有太大问题。</p>

<p>Apple给出了几个典型的应用情景，比如一个电视节目类的应用，当用户标记某些剧目为喜爱时，当这些剧有更新时，可以给用户发送静默的唤醒推送通知，客户端在接到通知后检查更新并开始后台下载（注意后台下载的部分绝对不应该在推送回调中做，而是应该使用新的后台传输服务，后面详细介绍）。下载完成后发送一个本地推送告知用户新的内容已经准备完毕。这样在用户注意到推送并打开应用的时候，所有必要的内容已经下载完毕，UI也将切换至用户喜爱的剧目，用户只需要点击播放即可开始真正使用应用，这绝对是无比顺畅和优秀的体验。另一种应用情景是文件同步类，比如用户标记了一些文件为需要随时同步，这样用户在其他设备或网页服务上更改了这些文件时，可以发送静默推送然后使用后台传输来保持这些文件随时是最新。</p>

<p>如果您是一路看下来的话，不难发现其实后台获取和静默推送在很多方面是很类似的，特别是实现和处理的方式，但是它们适用的情景是完全不同的。后台获取更多地使用在泛数据模式下，也即用户对特定数据并不是很关心，数据应该被更新的时间也不是很确定，典型的有社交类应用和天气类应用；而静默推送或者是推送唤醒更多地应该是用户感兴趣的内容发生更新时被使用，比如消息类应用和内容型服务等。根据不同的应用情景，选择合适的后台策略（或者混合使用两者），以带给用户绝佳体验，这是Apple所期望iOS7开发者做到的。</p>

<h3>后台传输（￼Background Transfer Service）</h3>

<p>iOS6和之前，iOS应用在大块数据的下载这一块限制是比较多的：只有应用在前台时能保持下载（用户按Home键切到后台或者是等到设备自动休眠都可能中止下载），在后台只有很短的最多十分钟时间可以保持网络连接。如果想要完成一个较大数据的下载，用户将不得不打开你的app并且基本无所事事。很多这种时候，用户会想要是在下载的时候能切到别的应用刷刷微博或者玩玩游戏，然后再切回来的就已经下载完成了的话，该有多好。iOS7中，这可以实现了。iOS7引入了后台传输的相关方式，用来保证应用退出后数据下载或者上传能继续进行。这种传输是由iOS系统进行管理的，没有时间限制，也不要求应用运行在前台。</p>

<p>想要实现后台传输，就必须使用iOS7的新的网络连接的类，NSURLSession。这是iOS7中引入用以替代陈旧的NSURLConnection的类，著名的AFNetworking甚至不惜从底层开始完全重写以适配iOS7和NSURLSession（参见<a href="https://github.com/AFNetworking/AFNetworking/wiki/AFNetworking-2.0-Migration-Guide">这里</a>），NSURLSession的重要性可见一斑。在这里我主要只介绍NSURLSession在后台传输中的一些使用，关于这个类的其他用法和对原有NSURLConnection的加强，只做稍微带过而不展开，有兴趣深入挖掘和使用的童鞋可以参看Apple的文档（或者更简单的方式是使用AFNetworking来处理网络相关内容，而不是直接和CFNetwork框架打交道）。</p>

<h4>步骤和例子</h4>

<p>后台传输的的实现也十分简单，简单说分为三个步骤：创建后台传输用的NSURLSession对象；向这个对象中加入对应的传输的NSURLSessionTask，并开始传输；在实现appDelegate里实现<code>-application:handleEventsForBackgroundURLSession:completionHandler:</code>方法，以刷新UI及通知系统传输结束。接下来结合代码来看一看实际的用法吧～</p>

<p>首先我们需要一个用于后台下载的session：</p>

<p>```objc
- (NSURLSession *)backgroundSession
{</p>

<pre><code>//Use dispatch_once_t to create only one background session. If you want more than one session, do with different identifier
static NSURLSession *session = nil;
static dispatch_once_t onceToken;
dispatch_once(&amp;onceToken, ^{
    NSURLSessionConfiguration *configuration = [NSURLSessionConfiguration backgroundSessionConfiguration:@"com.yourcompany.appId.BackgroundSession"];
    session = [NSURLSession sessionWithConfiguration:configuration delegate:self delegateQueue:nil];
});
return session;
</code></pre>

<p>}
```
这里创建并配置了NSURLSession，将其指定为后台session并设定delegate。</p>

<p>接下来向其中加入对应的传输用的NSURLSessionTask，并启动下载。</p>

<p>```objc
//@property (nonatomic) NSURLSession <em>session;
//@property (nonatomic) NSURLSessionDownloadTask </em>downloadTask;</p>

<ul>
<li><p>(NSURLSession *)backgroundSession
{
  //...
}</p></li>
<li><p>(void) beginDownload
{
  NSURL <em>downloadURL = [NSURL URLWithString:DownloadURLString];
  NSURLRequest </em>request = [NSURLRequest requestWithURL:downloadURL];
  self.session = [self backgroundSession];
  self.downloadTask = [self.session downloadTaskWithRequest:request];
  [self.downloadTask resume];
}
```</p></li>
</ul>


<p>最后一步是在appDelegate中实现<code>-application:handleEventsForBackgroundURLSession:completionHandler:</code></p>

<p>```objc
//AppDelegate.m
- (void)application:(UIApplication <em>)application handleEventsForBackgroundURLSession:(NSString </em>)identifier
  completionHandler:(void (<sup>)())completionHandler</sup>
{</p>

<pre><code>//Check if all transfers are done, and update UI
//Then tell system background transfer over, so it can take new snapshot to show in App Switcher
completionHandler();

//You can also pop up a local notification to remind the user
//...
</code></pre>

<p>}
```</p>

<p>NSURLSession和对应的NSURLSessionTask有以下重要的delegate方法可以使用：</p>

<p>```objc
- (void)URLSession:(NSURLSession <em>)session downloadTask:(NSURLSessionDownloadTask </em>)downloadTask</p>

<pre><code>                          didFinishDownloadingToURL:(NSURL *)location;
</code></pre>

<ul>
<li>(void)URLSession:(NSURLSession <em>)session task:(NSURLSessionTask </em>)task

<pre><code>                     didCompleteWithError:(NSError *)error;
</code></pre>

<p>```</p></li>
</ul>


<p>一旦后台传输的状态发生变化（包括正常结束和失败）的时候，应用将被唤醒并运行appDelegate中的回调，接下来NSURLSessionTask的委托方法将在后台被调用。虽然上面的例子中直接在appDelegate中call了completionHandler，但是实际上更好的选择是在appDelegate中暂时持有completionHandler，然后在NSURLSessionTask的delegate方法中检查是否确实完成了传输并更新UI后，再调用completionHandler。另外，你的应用到现在为止只是在后台运行，想要提醒用户传输完成的话，也许你还需要在这个时候发送一个本地推送（记住在这个时候你的应用是可以执行代码的，虽然是在后台），这样用户可以注意到你的应用的变化并回到应用，并开始已经准备好数据和界面。</p>

<h4>一些限制</h4>

<p>首先，后台传输只会通过wifi来进行，用户大概也不会开心蜂窝数据的流量被后台流量用掉。后台下载的时间与以前的关闭应用后X分钟的模式不一样，而是为了节省电力变为离散式的下载，并与其他后台任务并发（比如接收邮件等）。另外还需要注意的是，对于下载后的内容不要忘记写到应用的目录下（一般来说这种可以重复获得的内容应该放到cache目录下），否则如果由于应用完全退出的情况导致没有保存到可再次访问的路径的话，那可就白做工了。</p>

<p>后台传输非常适合用于文件，照片或者追加游戏内容关卡等的下载，如果配合后台获取或者静默推送的话，相信可以完全很多很有趣，并且以前被限制而无法实现的功能。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[猫都能学会的Unity3D Shader入门指南（一）]]></title>
    <link href="http://onevcat.com/2013/07/shader-tutorial-1/"/>
    <updated>2013-07-23T23:14:00+09:00</updated>
    <id>http://onevcat.com/2013/07/shader-tutorial-1</id>
    <content type="html"><![CDATA[<p><img src="http://img.onevcat.com/2013/shader-tutorial-banner.jpg" alt="Unity Shader教程" /></p>

<h2>动机</h2>

<p>自己使用Unity3D也有一段时间了，但是很多时候是流于表面，更多地是把这个引擎简单地用作脚本控制，而对更深入一些的层次几乎没有了解。虽然说Unity引擎设计的初衷就是创建简单的不需要开发者操心的谁都能用的3D引擎，但是只是肤浅的使用，可能是无法达到随心所欲的境地的，因此，这种状况必须改变！从哪里开始呢，貌似有句话叫做会写Shader的都是高手，于是，想大概看看从Shader开始能不能使自己到达的层次能再深入一些吧，再于是，有了这个系列（希望我能坚持写完它，虽然应该会拖个半年左右）。</p>

<p>Unity3D的所有渲染工作都离不开着色器（Shader），如果你和我一样最近开始对Shader编程比较感兴趣的话，可能你和我有着同样的困惑：如何开始？Unity3D提供了一些Shader的手册和文档（比如<a href="http://docs.unity3d.com/Documentation/Manual/Shaders.html">这里</a>，<a href="http://docs.unity3d.com/Documentation/Components/Built-inShaderGuide.html">这里</a>和<a href="http://docs.unity3d.com/Documentation/Components/SL-Reference.html">这里</a>），但是一来内容比较分散，二来学习阶梯稍微陡峭了些。这对于像我这样之前完全没有接触过有关内容的新人来说是相当不友好的。国内外虽然也有一些Shader的介绍和心得，但是也同样存在内容分散的问题，很多教程前一章就只介绍了基本概念，接下来马上就搬出一个超复杂的例子，对于很多基本的用法并没有解释。也许对于Shader熟练使用的开发者来说是没有问题，但是我相信像我这样的入门者也并不在少数。在多方寻觅无果后，我觉得有必要写一份教程，来以一个入门者的角度介绍一些Shader开发的基本步骤。其实与其说是教程，倒不如说是一份自我总结，希望能够帮到有需要的人。</p>

<p>所以，本“教程”的对象是</p>

<ul>
<li>总的来说是新接触Shader开发的人：也许你知道什么是Shader，也会使用别人的Shader，但是仅限于知道一些基本的内建Shader名字，从来没有打开它们查看其源码。</li>
<li>想要更多了解Shader和有需求要进行Shader开发的开发者，但是之前并没有Shader开发的经验。</li>
</ul>


<p>当然，因为我本身在Shader开发方面也是一个不折不扣的大菜鸟，本文很多内容也只是在自己的理解加上一些可能不太靠谱的求证和总结。本文中的示例应该会有更好的方式来实现，因此您是高手并且恰巧路过的话，如果有好的方式来实现某些内容，恳请您不吝留下评论，我会对本文进行不断更新和维护。</p>

<!--more-->


<h2>一些基本概念</h2>

<h3>Shader和Material</h3>

<p>如果是进行3D游戏开发的话，想必您对着两个词不会陌生。Shader（着色器）实际上就是一小段程序，它负责将输入的Mesh（网格）以指定的方式和输入的贴图或者颜色等组合作用，然后输出。绘图单元可以依据这个输出来将图像绘制到屏幕上。输入的贴图或者颜色等，加上对应的Shader，以及对Shader的特定的参数设置，将这些内容（Shader及输入参数）打包存储在一起，得到的就是一个Material（材质）。之后，我们便可以将材质赋予合适的renderer（渲染器）来进行渲染（输出）了。</p>

<p>所以说Shader并没有什么特别神奇的，它只是一段规定好输入（颜色，贴图等）和输出（渲染器能够读懂的点和颜色的对应关系）的程序。而Shader开发者要做的就是根据输入，进行计算变换，产生输出而已。</p>

<p>Shader大体上可以分为两类，简单来说</p>

<ul>
<li>表面着色器（Surface Shader） - 为你做了大部分的工作，只需要简单的技巧即可实现很多不错的效果。类比卡片机，上手以后不太需要很多努力就能拍出不错的效果。</li>
<li>片段着色器（Fragment Shader） - 可以做的事情更多，但是也比较难写。使用片段着色器的主要目的是可以在比较低的层级上进行更复杂（或者针对目标设备更高效）的开发。</li>
</ul>


<p>因为是入门文章，所以之后的介绍将主要集中在表面着色器上。</p>

<h3>Shader程序的基本结构</h3>

<p>因为着色器代码可以说专用性非常强，因此人为地规定了它的基本结构。一个普通的着色器的结构应该是这样的：
<img src="http://img.onevcat.com/2013/shader-structure.png" alt="一段Shader程序的结构" /></p>

<p>首先是一些属性定义，用来指定这段代码将有哪些输入。接下来是一个或者多个的子着色器，在实际运行中，哪一个子着色器被使用是由运行的平台所决定的。子着色器是代码的主体，每一个子着色器中包含一个或者多个的Pass。在计算着色时，平台先选择最优先可以使用的着色器，然后依次运行其中的Pass，然后得到输出的结果。最后指定一个回滚，用来处理所有Subshader都不能运行的情况（比如目标设备实在太老，所有Subshader中都有其不支持的特性）。</p>

<p>需要提前说明的是，在实际进行表面着色器的开发时，我们将直接在Subshader这个层次上写代码，系统将把我们的代码编译成若干个合适的Pass。废话到此为止，下面让我们真正实际进入Shader的世界吧。</p>

<h2>Hello Shader</h2>

<p>百行文档不如一个实例，下面给出一段简单的Shader代码，然后根据代码来验证下上面说到的结构和阐述一些基本的Shader语法。因为本文是针对Unity3D来写Shader的，所以也使用Unity3D来演示吧。首先，新建一个Shader，可以在Project面板中找到，Create，选择Shader，然后将其命名为<code>Diffuse Texture</code>：</p>

<p><img src="http://img.onevcat.com/2013/shader-create-in-unity.png" alt="在Unity3D中新建一个Shader" /></p>

<p>随便用个文本编辑器打开刚才新建的Shader：</p>

<p>```glsl
Shader "Custom/Diffuse Texture" {</p>

<pre><code>Properties {
    _MainTex ("Base (RGB)", 2D) = "white" {}
}
SubShader {
    Tags { "RenderType"="Opaque" }
    LOD 200

    CGPROGRAM
    #pragma surface surf Lambert

    sampler2D _MainTex;

    struct Input {
        float2 uv_MainTex;
    };

    void surf (Input IN, inout SurfaceOutput o) {
        half4 c = tex2D (_MainTex, IN.uv_MainTex);
        o.Albedo = c.rgb;
        o.Alpha = c.a;
    }
    ENDCG
} 
FallBack "Diffuse"
</code></pre>

<p>}</p>

<p>```</p>

<p>如果您之前没怎么看过Shader代码的话，估计细节上会看不太懂。但是有了上面基本结构的介绍，您应该可以识别出这个Shader的构成，比如一个Properties部分，一个SubShader，以及一个FallBack。另外，第一行只是这个Shader的声明并为其指定了一个名字，比如我们的实例Shader，你可以在材质面板选择Shader时在对应的位置找到这个Shader。</p>

<p><img src="http://img.onevcat.com/2013/shader-select.png" alt="在Unity3D中找到刚才新建的Shader" /></p>

<p><strong>接下来我们讲逐句讲解这个Shader，以期明了每一个语句的意义。</strong></p>

<h3>属性</h3>

<p>在<code>Properties{}</code>中定义着色器属性，在这里定义的属性将被作为输入提供给所有的子着色器。每一条属性的定义的语法是这样的：</p>

<p><code>_Name("Display Name", type) = defaultValue[{options}]</code></p>

<ul>
<li>_Name - 属性的名字，简单说就是变量名，在之后整个Shader代码中将使用这个名字来获取该属性的内容</li>
<li>Display Name - 这个字符串将显示在Unity的材质编辑器中作为Shader的使用者可读的内容</li>
<li>type - 这个属性的类型，可能的type所表示的内容有以下几种：

<ul>
<li>Color - 一种颜色，由RGBA（红绿蓝和透明度）四个量来定义；</li>
<li>2D - 一张2的阶数大小（256，512之类）的贴图。这张贴图将在采样后被转为对应基于模型UV的每个像素的颜色，最终被显示出来；</li>
<li>Rect - 一个非2阶数大小的贴图；</li>
<li>Cube - 即Cube map texture（立方体纹理），简单说就是6张有联系的2D贴图的组合，主要用来做反射效果（比如天空盒和动态反射），也会被转换为对应点的采样；</li>
<li>Range(min, max) - 一个介于最小值和最大值之间的浮点数，一般用来当作调整Shader某些特性的参数（比如透明度渲染的截止值可以是从0至1的值等）；</li>
<li>Float - 任意一个浮点数；</li>
<li>Vector - 一个四维数；</li>
</ul>
</li>
<li>defaultValue 定义了这个属性的默认值，通过输入一个符合格式的默认值来指定对应属性的初始值（某些效果可能需要某些特定的参数值来达到需要的效果，虽然这些值可以在之后在进行调整，但是如果默认就指定为想要的值的话就省去了一个个调整的时间，方便很多）。

<ul>
<li>Color - 以0～1定义的rgba颜色，比如(1,1,1,1)；</li>
<li>2D/Rect/Cube - 对于贴图来说，默认值可以为一个代表默认tint颜色的字符串，可以是空字符串或者"white","black","gray","bump"中的一个</li>
<li>Float，Range - 某个指定的浮点数</li>
<li>Vector - 一个4维数，写为 (x,y,z,w)</li>
</ul>
</li>
<li>另外还有一个{option}，它只对2D，Rect或者Cube贴图有关，在写输入时我们最少要在贴图之后写一对什么都不含的空白的{}，当我们需要打开特定选项时可以把其写在这对花括号内。如果需要同时打开多个选项，可以使用空白分隔。可能的选择有ObjectLinear, EyeLinear, SphereMap, CubeReflect, CubeNormal中的一个，这些都是OpenGL中TexGen的模式，具体的留到后面有机会再说。</li>
</ul>


<p>所以，一组属性的申明看起来也许会是这个样子的</p>

<p><code>glsl
//Define a color with a default value of semi-transparent blue
_MainColor ("Main Color", Color) = (0,0,1,0.5)
//Define a texture with a default of white
_Texture ("Texture", 2D) = "white" {}
</code></p>

<p>现在看懂上面那段Shader（以及其他所有Shader）的Properties部分应该不会有任何问题了。接下来就是SubShader部分了。</p>

<h3>Tags</h3>

<p>表面着色器可以被若干的标签（tags）所修饰，而硬件将通过判定这些标签来决定什么时候调用该着色器。比如我们的例子中SubShader的第一句</p>

<p><code>Tags { "RenderType"="Opaque" }</code></p>

<p>告诉了系统应该在渲染非透明物体时调用我们。Unity定义了一些列这样的渲染过程，与RenderType是Opaque相对应的显而易见的是<code>"RenderType" = "Transparent"</code>，表示渲染含有透明效果的物体时调用。在这里Tags其实暗示了你的Shader输出的是什么，如果输出中都是非透明物体，那写在Opaque里；如果想渲染透明或者半透明的像素，那应该写在Transparent中。</p>

<p>另外比较有用的标签还有<code>"IgnoreProjector"="True"</code>（不被<a href="http://docs.unity3d.com/Documentation/Components/class-Projector.html">Projectors</a>影响），<code>"ForceNoShadowCasting"="True"</code>（从不产生阴影）以及<code>"Queue"="xxx"</code>（指定渲染顺序队列）。这里想要着重说一下的是Queue这个标签，如果你使用Unity做过一些透明和不透明物体的混合的话，很可能已经遇到过不透明物体无法呈现在透明物体之后的情况。这种情况很可能是由于Shader的渲染顺序不正确导致的。Queue指定了物体的渲染顺序，预定义的Queue有：</p>

<ul>
<li>Background - 最早被调用的渲染，用来渲染天空盒或者背景</li>
<li>Geometry - 这是默认值，用来渲染非透明物体（普通情况下，场景中的绝大多数物体应该是非透明的）</li>
<li>AlphaTest - 用来渲染经过<a href="http://docs.unity3d.com/Documentation/Components/SL-AlphaTest.html">Alpha Test</a>的像素，单独为AlphaTest设定一个Queue是出于对效率的考虑</li>
<li>Transparent - 以从后往前的顺序渲染透明物体</li>
<li>Overlay - 用来渲染叠加的效果，是渲染的最后阶段（比如镜头光晕等特效）</li>
</ul>


<p>这些预定义的值本质上是一组定义整数，Background = 1000， Geometry = 2000, AlphaTest = 2450， Transparent = 3000，最后Overlay = 4000。在我们实际设置Queue值时，不仅能使用上面的几个预定义值，我们也可以指定自己的Queue值，写成类似这样：<code>"Queue"="Transparent+100"</code>，表示一个在Transparent之后100的Queue上进行调用。通过调整Queue值，我们可以确保某些物体一定在另一些物体之前或者之后渲染，这个技巧有时候很有用处。</p>

<h3>LOD</h3>

<p>LOD很简单，它是Level of Detail的缩写，在这里例子里我们指定了其为200（其实这是Unity的内建Diffuse着色器的设定值）。这个数值决定了我们能用什么样的Shader。在Unity的Quality Settings中我们可以设定允许的最大LOD，当设定的LOD小于SubShader所指定的LOD时，这个SubShader将不可用。Unity内建Shader定义了一组LOD的数值，我们在实现自己的Shader的时候可以将其作为参考来设定自己的LOD数值，这样在之后调整根据设备图形性能来调整画质时可以进行比较精确的控制。</p>

<ul>
<li>VertexLit及其系列 = 100</li>
<li>Decal, Reflective VertexLit = 150</li>
<li>Diffuse = 200</li>
<li>Diffuse Detail, Reflective Bumped Unlit, Reflective Bumped VertexLit = 250</li>
<li>Bumped, Specular = 300</li>
<li>Bumped Specular = 400</li>
<li>Parallax = 500</li>
<li>Parallax Specular = 600</li>
</ul>


<h3>Shader本体</h3>

<p>前面杂项说完了，终于可以开始看看最主要的部分了，也就是将输入转变为输出的代码部分。为了方便看，请容许我把上面的SubShader的主题部分抄写一遍</p>

<p>```glsl
CGPROGRAM</p>

<h1>pragma surface surf Lambert</h1>

<p>sampler2D _MainTex;</p>

<p>struct Input {</p>

<pre><code>float2 uv_MainTex;
</code></pre>

<p>};</p>

<p>void surf (Input IN, inout SurfaceOutput o) {</p>

<pre><code>half4 c = tex2D (_MainTex, IN.uv_MainTex);
o.Albedo = c.rgb;
o.Alpha = c.a;
</code></pre>

<p>}
ENDCG
```</p>

<p>还是逐行来看，首先是CGPROGRAM。这是一个开始标记，表明从这里开始是一段CG程序（我们在写Unity的Shader时用的是Cg/HLSL语言）。最后一行的ENDCG与CGPROGRAM是对应的，表明CG程序到此结束。</p>

<p>接下来是是一个编译指令：<code>#pragma surface surf Lambert</code>，它声明了我们要写一个表面Shader，并指定了光照模型。它的写法是这样的</p>

<p><code>#pragma surface surfaceFunction lightModel [optionalparams]</code></p>

<ul>
<li>surface - 声明的是一个表面着色器</li>
<li>surfaceFunction - 着色器代码的方法的名字</li>
<li>lightModel - 使用的光照模型。</li>
</ul>


<p>所以在我们的例子中，我们声明了一个表面着色器，实际的代码在surf函数中（在下面能找到该函数），使用Lambert（也就是普通的diffuse）作为光照模型。</p>

<p>接下来一句<code>sampler2D _MainTex;</code>，sampler2D是个啥？其实在CG中，sampler2D就是和texture所绑定的一个数据容器接口。等等..这个说法还是太复杂了，简单理解的话，所谓加载以后的texture（贴图）说白了不过是一块内存存储的，使用了RGB（也许还有A）通道，且每个通道8bits的数据。而具体地想知道像素与坐标的对应关系，以及获取这些数据，我们总不能一次一次去自己计算内存地址或者偏移，因此可以通过sampler2D来对贴图进行操作。更简单地理解，sampler2D就是GLSL中的2D贴图的类型，相应的，还有sampler1D，sampler3D，samplerCube等等格式。</p>

<p>解释通了sampler2D是什么之后，还需要解释下为什么在这里需要一句对<code>_MainTex</code>的声明，之前我们不是已经在<code>Properties</code>里声明过它是贴图了么。答案是我们用来实例的这个shader其实是由两个相对独立的块组成的，外层的属性声明，回滚等等是Unity可以直接使用和编译的ShaderLab；而现在我们是在<code>CGPROGRAM...ENDCG</code>这样一个代码块中，这是一段CG程序。对于这段CG程序，要想访问在<code>Properties</code>中所定义的变量的话，<strong>必须使用和之前变量相同的名字进行声明</strong>。于是其实<code>sampler2D _MainTex;</code>做的事情就是再次声明并链接了_MainTex，使得接下来的CG程序能够使用这个变量。</p>

<p>终于可以继续了。接下来是一个struct结构体。相信大家对于结构体已经很熟悉了，我们先跳过之，直接看下面的的surf函数。上面的#pragma段已经指出了我们的着色器代码的方法的名字叫做surf，那没跑儿了，就是这段代码是我们的着色器的工作核心。我们已经说过不止一次，着色器就是给定了输入，然后给出输出进行着色的代码。CG规定了声明为表面着色器的方法（就是我们这里的surf）的参数类型和名字，因此我们没有权利决定surf的输入输出参数的类型，只能按照规定写。这个规定就是第一个参数是一个Input结构，第二个参数是一个inout的SurfaceOutput结构。</p>

<p>它们分别是什么呢？Input其实是需要我们去定义的结构，这给我们提供了一个机会，可以把所需要参与计算的数据都放到这个Input结构中，传入surf函数使用；SurfaceOutput是已经定义好了里面类型输出结构，但是一开始的时候内容暂时是空白的，我们需要向里面填写输出，这样就可以完成着色了。先仔细看看INPUT吧，现在可以跳回来看上面定义的INPUT结构体了：</p>

<p>```glsl
struct Input {</p>

<pre><code>float2 uv_MainTex;
</code></pre>

<p>};
```</p>

<p>作为输入的结构体必须命名为Input，这个结构体中定义了一个float2的变量…你没看错我也没打错，就是float2，表示浮点数的float后面紧跟一个数字2，这又是什么意思呢？其实没什么魔法，float和vec都可以在之后加入一个2到4的数字，来表示被打包在一起的2到4个同类型数。比如下面的这些定义：</p>

<p><code>
//Define a 2d vector variable
vec2 coordinate;
//Define a color variable
float4 color;
//Multiply out a color
float3 multipliedColor = color.rgb * coordinate.x;
</code></p>

<p>在访问这些值时，我们即可以只使用名称来获得整组值，也可以使用下标的方式（比如.xyzw，.rgba或它们的部分比如.x等等）来获得某个值。在这个例子里，我们声明了一个叫做<code>uv_MainTex</code>的包含两个浮点数的变量。</p>

<p>如果你对3D开发稍有耳闻的话，一定不会对uv这两个字母感到陌生。UV mapping的作用是将一个2D贴图上的点按照一定规则映射到3D模型上，是3D渲染中最常见的一种顶点处理手段。在CG程序中，我们有这样的约定，在一个贴图变量（在我们例子中是<code>_MainTex</code>）之前加上uv两个字母，就代表提取它的uv值（其实就是两个代表贴图上点的二维坐标 ）。我们之后就可以在surf程序中直接通过访问uv_MainTex来取得这张贴图当前需要计算的点的坐标值了。</p>

<p>如果你坚持看到这里了，那要恭喜你，因为离最后成功读完一个Shader只有一步之遥。我们回到surf函数，它的两有参数，第一个是Input，我们已经明白了：在计算输出时Shader会多次调用surf函数，每次给入一个贴图上的点坐标，来计算输出。第二个参数是一个可写的SurfaceOutput，SurfaceOutput是预定义的输出结构，我们的surf函数的目标就是根据输入把这个输出结构填上。SurfaceOutput结构体的定义如下</p>

<p>```glsl
struct SurfaceOutput {</p>

<pre><code>half3 Albedo;     //像素的颜色
half3 Normal;     //像素的法向值
half3 Emission;   //像素的发散颜色
half Specular;    //像素的镜面高光
half Gloss;       //像素的发光强度
half Alpha;       //像素的透明度
</code></pre>

<p>};
```</p>

<p>这里的half和我们常见float与double类似，都表示浮点数，只不过精度不一样。也许你很熟悉单精度浮点数（float或者single）和双精度浮点数（double），这里的half指的是半精度浮点数，精度最低，运算性能相对比高精度浮点数高一些，因此被大量使用。</p>

<p>在例子中，我们做的事情非常简单：</p>

<p><code>glsl
half4 c = tex2D (_MainTex, IN.uv_MainTex);
o.Albedo = c.rgb;
o.Alpha = c.a;
</code></p>

<p>这里用到了一个<code>tex2d</code>函数，这是CG程序中用来在一张贴图中对一个点进行采样的方法，返回一个float4。这里对_MainTex在输入点上进行了采样，并将其颜色的rbg值赋予了输出的像素颜色，将a值赋予透明度。于是，着色器就明白了应当怎样工作：即找到贴图上对应的uv点，直接使用颜色信息来进行着色，over。</p>

<h2>接下来...</h2>

<p>我想现在你已经能读懂一些最简单的Shader了，接下来我推荐的是参考Unity的<a href="http://docs.unity3d.com/Documentation/Components/SL-SurfaceShaderExamples.html">Surface Shader Examples</a>多接触一些各种各样的基本Shader。在这篇教程的基础上，配合一些google的工作，完全看懂这个shader示例页面应该不成问题。如果能做到无压力看懂，那说明你已经有良好的基础可以前进到Shader的更深的层次了（也许等不到我的下一篇教程就可以自己开始动手写些效果了）；如果暂时还是有困难，那也没有关系，Shader学习绝对是一个渐进的过程，因为有很多约定和常用技巧，多积累和实践自然会进步并掌握。</p>

<p>在接下来的教程里，打算通过介绍一些实际例子以及从基础开始实际逐步动手实现一个复杂一点的例子，让我们能看到shader在真正使用中的威力。我希望能尽快写完这个系列，但是无奈时间确实有限，所以我也不知道什么时候能出炉...写好的时候我会更改这段内容并指向新的文章。您要是担心错过的话，也可以使用<a href="http://eepurl.com/wNSkj">邮件订阅</a>或者<a href="http://onevcat.com/atom.xml">订阅本站的rss</a>(虽然Google Reader已经关了- -)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WWDC 2013 Session笔记 - UIKit Dynamics入门]]></title>
    <link href="http://onevcat.com/2013/06/uikit-dynamics-started/"/>
    <updated>2013-06-15T15:11:00+09:00</updated>
    <id>http://onevcat.com/2013/06/uikit-dynamics-started</id>
    <content type="html"><![CDATA[<p>这是我的WWDC2013系列笔记中的一篇，完整的笔记列表请参看<a href="http://onevcat.com/2013/06/developer-should-know-about-ios7/">这篇总览</a>。本文仅作为个人记录使用，也欢迎在<a href="http://creativecommons.org/licenses/by-nc/3.0/deed.zh">许可协议</a>范围内转载或使用，但是还烦请保留原文链接，谢谢您的理解合作。如果您觉得本站对您能有帮助，您可以使用<a href="http://onevcat.com/atom.xml">RSS</a>或<a href="http://eepurl.com/wNSkj">邮件</a>方式订阅本站，这样您将能在第一时间获取本站信息。</p>

<p>本文涉及到的WWDC2013 Session有</p>

<ul>
<li>Session 206 Getting Started with UIKit Dynamics</li>
<li>Session 221 Advanced Techniques with UIKit Dynamics</li>
</ul>


<h3>什么是UIKit动力学（UIKit Dynamics）</h3>

<p>其实就是UIKit的一套动画和交互体系。我们现在进行UI动画基本都是使用CoreAnimation或者UIView animations。而UIKit动力学最大的特点是将现实世界动力驱动的动画引入了UIKit，比如重力，铰链连接，碰撞，悬挂等效果。一言蔽之，即是，将2D物理引擎引入了人UIKit。需要注意，UIKit动力学的引入，并不是以替代CA或者UIView动画为目的的，在绝大多数情况下CA或者UIView动画仍然是最优方案，只有在需要引入逼真的交互设计的时候，才需要使用UIKit动力学它是作为现有交互设计和实现的一种补充而存在的。</p>

<p>目的当然是更加自然和炫目的UI动画效果，比如模拟现实的拖拽和弹性效果，放在以前如果单用iOS SDK的动画实现起来还是相当困难的，而在UIKit Dynamics的帮助下，复杂的动画效果可能也只需要很短的代码（基本100行以内...其实现在用UIView animation想实现一个不太复杂的动画所要的代码行数都不止这个数了吧）。总之，便利多多，配合UI交互设计，以前很多不敢想和不敢写（至少不敢自己写）的效果实现起来会非常方便，也相信在iOS7的时代各色使用UIKit动力学的应用的在动画效果肯定会上升一个档次。</p>

<h3>那么，应该怎么做呢</h3>

<h4>UIKit动力学实现的结构</h4>

<p>为了实现动力UI，需要注册一套UI行为的体系，之后UI便会按照预先的设定进行运动了。我们应该了解的新的基本概念有如下四个：</p>

<!--more-->


<ul>
<li>UIDynamicItem：用来描述一个力学物体的状态，其实就是实现了UIDynamicItem委托的对象，或者抽象为有面积有旋转的质点；</li>
<li>UIDynamicBehavior：动力行为的描述，用来指定UIDynamicItem应该如何运动，即定义适用的物理规则。一般我们使用这个类的子类对象来对一组UIDynamicItem应该遵守的行为规则进行描述；</li>
<li>UIDynamicAnimator；动画的播放者，动力行为（UIDynamicBehavior）的容器，添加到容器内的行为将发挥作用；</li>
<li>ReferenceView：等同于力学参考系，如果你的初中物理不是语文老师教的话，我想你知道这是啥..只有当想要添加力学的UIView是ReferenceView的子view时，动力UI才发生作用。</li>
</ul>


<p>光说不练假把式，来做点简单的demo吧。比如为一个view添加重力行为：</p>

<p>```objc
- (void)viewDidLoad
{</p>

<pre><code>[super viewDidLoad];

UIView *aView = [[UIView alloc] initWithFrame:CGRectMake(100, 50, 100, 100)];
aView.backgroundColor = [UIColor lightGrayColor];
[self.view addSubview:aView];

UIDynamicAnimator* animator = [[UIDynamicAnimator alloc] initWithReferenceView:self.view];
UIGravityBehavior* gravityBeahvior = [[UIGravityBehavior alloc] initWithItems:@[aView]];
[animator addBehavior:gravityBeahvior];
self.animator = animator;
</code></pre>

<p>}
```
代码很简单，</p>

<ol>
<li>以现在ViewController的view为参照系（ReferenceView），来初始化一个UIDynamicAnimator。</li>
<li>然后分配并初始化一个动力行为，这里是UIGravityBehavior，将需要进行物理模拟的UIDynamicItem传入。<code>UIGravityBehavior</code>的<code>initWithItems:</code>接受的参数为包含id<UIDynamicItem>的数组，另外<code>UIGravityBehavior</code>实例还有一个<code>addItem:</code>方法接受单个的id<UIDynamicItem>。就是说，实现了UIDynamicItem委托的对象，都可以看作是被力学特性影响的，进而参与到计算中。UIDynamicItem委托需要我们实现<code>bounds</code>，<code>center</code>和<code>transform</code>三个属性，在UIKit Dynamics计算新的位置时，需要向Behavior内的item询问这些参数，以进行正确计算。iOS7中，UIView和UICollectionViewLayoutAttributes已经默认实现了这个接口，所以这里我们直接把需要模拟重力的UIView添加到UIGravityBehavior里就行了。</li>
<li>把配置好的UIGravityBehavior添加到animator中。</li>
<li>strong持有一下animator，避免当前scope结束被ARC释放掉（后果当然就是UIView在哪儿傻站着不掉）</li>
</ol>


<p>运行结果，view开始受重力影响了：</p>

<p><img src="http://img.onevcat.com/2013/uikit-dynamics-gravity.gif" alt="重力作用下的UIview" /></p>

<h4>碰撞，我要碰撞</h4>

<p>没有碰撞的话，物理引擎就没有任何意义了。和重力行为类似，碰撞也有一个<code>UIDynamicBehavior</code>子类来描述碰撞行为，即<code>UICollisionBehavior</code>。在上面的demo中加上几句：</p>

<p>```objc
- (void)viewDidLoad
{</p>

<pre><code>[super viewDidLoad];

UIView *aView = [[UIView alloc] initWithFrame:CGRectMake(100, 50, 100, 100)];
aView.backgroundColor = [UIColor lightGrayColor];
[self.view addSubview:aView];

UIDynamicAnimator* animator = [[UIDynamicAnimator alloc] initWithReferenceView:self.view];
UIGravityBehavior* gravityBeahvior = [[UIGravityBehavior alloc] initWithItems:@[aView]];
[animator addBehavior:gravityBeahvior];

UICollisionBehavior* collisionBehavior = [[UICollisionBehavior alloc] initWithItems:@[aView]];
collisionBehavior.translatesReferenceBoundsIntoBoundary = YES;
[animator addBehavior:collisionBehavior];
collisionBehavior.collisionDelegate = self;

self.animator = animator;
</code></pre>

<p>}
```</p>

<p>也许聪明的你已经看到了，还是一样的，创建新的行为规则（UICollisionBehavior），然后加到animator中…唯一区别的地方是碰撞需要设定碰撞边界范围translatesReferenceBoundsIntoBoundary将整个参照view（也就是self.view）的边框作为碰撞边界（另外你还可以使用setTranslatesReferenceBoundsIntoBoundaryWithInsets:这样的方法来设定某一个区域作为碰撞边界，更复杂的边界可以使用addBoundaryWithIdentifier:forPath:来添加UIBezierPath，或者addBoundaryWithIdentifier:fromPoint:toPoint:来添加一条线段为边界，详细地还请查阅文档）；另外碰撞是有回调的，可以在self中实现<code>UICollisionBehaviorDelegate</code>。</p>

<p>最后，只是直直地掉下来的话未免太无聊了，加个角度吧：</p>

<p><code>objc
aView.transform = CGAffineTransformRotate(aView.transform, 45);
</code></p>

<p>结果是这样的，帅死了…这在以前只用iOS SDK的话，够写上很长时间了吧..</p>

<p><img src="http://img.onevcat.com/2013/uikit-dynamics-collider.gif" alt="碰撞和重力同时作用的动力UI" /></p>

<p>碰撞的delegate可以帮助我们了解碰撞的具体情况，包括哪个item和哪个item开始发生碰撞，碰撞接触点是什么，是否和边界碰撞，和哪个边界碰撞了等信息。这些回调方法保持了Apple一向的命名原则，所以通俗易懂。需要多说一句的是回调方法中对于ReferenceView的Bounds做边界的情况，BoundaryIdentifier将会是nil，自行添加的其他边界的话，ID自然是添加时指定的ID了。</p>

<ul>
<li>– collisionBehavior:beganContactForItem:withBoundaryIdentifier:atPoint:</li>
<li>– collisionBehavior:beganContactForItem:withItem:atPoint:</li>
<li>– collisionBehavior:endedContactForItem:withBoundaryIdentifier:</li>
<li>– collisionBehavior:endedContactForItem:withItem:</li>
</ul>


<h4>其他能实现的效果</h4>

<p>除了重力和碰撞，iOS SDK还预先帮我们实现了一些其他的有用的物理行为，它们包括</p>

<ul>
<li>UIAttachmentBehavior 描述一个view和一个锚相连接的情况，也可以描述view和view之间的连接。attachment描述的是两个点之间的连接情况，可以通过设置来模拟无形变或者弹性形变的情况（再次希望你还记得这些概念，简单说就是木棒连接和弹簧连接两个物体）。当然，在多个物体间设定多个；UIAttachmentBehavior，就可以模拟多物体连接了..有了这些，似乎可以做个老鹰捉小鸡的游戏了- -…</li>
<li>UISnapBehavior 将UIView通过动画吸附到某个点上。初始化的时候设定一下UISnapBehavior的initWithItem:snapToPoint:就行，因为API非常简单，视觉效果也很棒，估计它是今后非游戏app里会被最常用的效果之一了；</li>
<li>UIPushBehavior 可以为一个UIView施加一个力的作用，这个力可以是持续的，也可以只是一个冲量。当然我们可以指定力的大小，方向和作用点等等信息。</li>
<li>UIDynamicItemBehavior 其实是一个辅助的行为，用来在item层级设定一些参数，比如item的摩擦，阻力，角阻力，弹性密度和可允许的旋转等等</li>
</ul>


<p>UIDynamicItemBehavior有一组系统定义的默认值，</p>

<ul>
<li>allowsRotation YES</li>
<li>density 1.0</li>
<li>elasticity 0.0</li>
<li>friction 0.0</li>
<li>resistance 0.0</li>
</ul>


<p>所有的UIDynamicBehavior都是可以独立作用的，同时作用时也遵守力的合成。也就是说，组合使用行为可以达到一些较复杂的效果。举个例子，希望模拟一个drag物体然后drop后下落的过程，可以用如下代码：</p>

<p>```objc
- (void)viewDidLoad
{</p>

<pre><code>[super viewDidLoad];

UIDynamicAnimator* animator = [[UIDynamicAnimator alloc] initWithReferenceView:self.view];
UICollisionBehavior* collisionBehavior = [[UICollisionBehavior alloc] initWithItems:@[self.square1]];

collisionBehavior.translatesReferenceBoundsIntoBoundary = YES;
[animator addBehavior:collisionBehavior];

UIGravityBehavior *g = [[UIGravityBehavior alloc] initWithItems:@[self.square1]];
[animator addBehavior:g];

self.animator = animator;
</code></pre>

<p>}</p>

<p>-(IBAction)handleAttachmentGesture:(UIPanGestureRecognizer*)gesture
{</p>

<pre><code>if (gesture.state == UIGestureRecognizerStateBegan){

    CGPoint squareCenterPoint = CGPointMake(self.square1.center.x, self.square1.center.y - 100.0);
    CGPoint attachmentPoint = CGPointMake(-25.0, -25.0);

    UIAttachmentBehavior* attachmentBehavior = [[UIAttachmentBehavior alloc] initWithItem:self.square1 point:attachmentPoint attachedToAnchor:squareCenterPoint];

    self.attachmentBehavior = attachmentBehavior;
    [self.animator addBehavior:attachmentBehavior];

} else if ( gesture.state == UIGestureRecognizerStateChanged) {

    [self.attachmentBehavior setAnchorPoint:[gesture locationInView:self.view]];

} else if (gesture.state == UIGestureRecognizerStateEnded) {
    [self.animator removeBehavior:self.attachmentBehavior];
}
</code></pre>

<p>}
```</p>

<p>viewDidiLoad时先在现在环境中加入了重力，然后监测到pan时附加一个UIAttachmentBehavior，并在pan位置更新更新其锚点，此时UIAttachmentBehavior和UIGravityBehavior将同时作用（想象成一根木棒连着手指处和view）。在手势结束时将这个UIAttachmentBehavior移除，view将在重力作用下下落。整个过程如下图：</p>

<p><img src="http://img.onevcat.com/2013/uikit-dynamics-dragdrop.gif" alt="Drag &amp; Drop" /></p>

<h3>UIKit力学的物理学分析</h3>

<p>既然是力学，那显然各种单位是很重要的。在现实世界中，理想情况下物体的运动符合牛顿第二运动定理，在国际单位制中，力的单位是牛顿（N），距离单位是米（m），时间单位是秒（s），质量单位是千克（kg）。根据地球妈妈的心情，我们生活在这样一套体制中：重力加速度约为9.8m/s<sup>2</sup> ，加速度的单位是m/s<sup>2</sup> ，速度单位是m/s，牛顿其实是kg·m/s<sup>2</sup> ，即1牛顿是让质量为1千克的物体产生1米每二次方秒的加速度所需要的力。</p>

<p>以上是帮助您回忆初中知识，而现在这一套体系在UIKit里又怎么样呢？这其实是每一个物理引擎都要讨论和明白的事情，UIKit的单位体制里由于m这个东西太过夸张，因此用等量化的点（point，之后简写为p）来代替。具体是这样的：UI重力加速度定义为1000p/s<sup>2</sup> ，这样的定义有两方面的考虑，一时为了简化，好记，确实1000比9.8来的只观好看，二是也算符合人们的直感：一个UIView从y=0开始自由落体落到屏幕底部所需的时间，在3.5寸屏幕上为0.98秒，4寸屏幕上为1.07秒，1秒左右的自由落体的视觉效果对人眼来说是很舒服能进行判断的。</p>

<p>那么UIView的质量又如何定义呢，这也是很重要的，并涉及到力作用和加速度下UIView的表现。苹果又给出了自己的“UIKit牛顿第二定律”，定义了1单位作用力相当于将一个100px100p的默认密度的UIView以100p/s<sup>2</sup> 的加速度移动。这里需要注意默认密度这个假设，因为在UIDynamicItem的委托中并没有实现任何密度相关的定义，而是通过UIDynamicItemBehavior来附加指定的。默认情况下，密度值为1，这就相当于质量是10000单位的UIView在1单位的作用力下可以达到1/10的UI重力加速度。</p>

<p>这样类比之后的结论是，如果将1单位的UI力学中的力等同于1牛顿的话：</p>

<ul>
<li>1000单位的UI质量，与现实世界中1kg的质量相当，即一个点等同一克；</li>
<li>屏幕的100像素的长度，约和现实世界中0.99米相当（完全可以看为1米）</li>
<li>UI力学中的默认密度，约和现实世界的0.1kg/m<sup>2</sup> 相当</li>
</ul>


<p>可以说UIKit为我们构建了一套适应iOS屏幕的相当优雅的力学系统，不仅让人过目不忘，在实际的物理情景和用户体验中也近乎完美。在开发中，我们可以参照这些关系寻找现实中的例子，然后将其带入UIKit的力学系统中，以得到良好的模拟效果。</p>

<h3>UIKit动力学自定义</h3>

<p>除了SDK预先定义好的行为以外，我们还可以自己定义想要的行为。这种定义可以发生在两个层级上，一种是将官方的行为打包，以简化实现。另一种是完全定义新的计算规则。</p>

<p>对于第一种，其实考虑一下上面的重力+边界碰撞，或者drag &amp; drop行为，其实都是两个甚至多个行为的叠加。要是每次都这样设定一次的话，不是很辛苦么，还容易遗忘出错。于是一种好的方式是将它们打包封装一下。具体地，如下步骤：</p>

<ol>
<li>继承一下UIDynamicBehavior（在这里UIDynamicBehavior类似一个抽象类，并没有具体实现什么行为）</li>
<li>在子类中实现一个类似其他内置行为初始化方法<code>initWithItems:</code>，用以添加物体和想要打包的规则。当然你如果喜欢用其他方式也行..只不过和自带的行为保持API统一对大家都有好处..添加item的话就用默认规则的initWithItems:就行，对于规则UIDynamicBehavior提供了一个addChildBehavior:的方法，来将其他规则加入到当前规则里</li>
<li>没有第三步了，使用就行了。</li>
</ol>


<p>一个例子，打包了碰撞和重力两种行为，定义之后使用时就只需要写一次了。当然这只是最简单的例子和运用，当行为复杂以后，这样的使用方法是不可避免的，否则管理起来会让人有想死的心。另外，将手势等交互的方式也集成之中，进一步封装调用细节会是不错的实践。</p>

<p>```objc
//GravityWithCollisionBehavior.h
@interface GravityWithCollisionBehavior : UIDynamicBehavior</p>

<p>-(instancetype) initWithItems:(NSArray *)items;</p>

<p>@end</p>

<p>//GravityWithCollisionBehavior.m
@implementation GravityWithCollisionBehavior</p>

<p>-(instancetype) initWithItems:(NSArray *)items
{</p>

<pre><code>if (self = [super init]) {
    UIGravityBehavior *gb = [[UIGravityBehavior alloc] initWithItems:items];
    UICollisionBehavior *cb = [[UICollisionBehavior alloc] initWithItems:items];
    cb.translatesReferenceBoundsIntoBoundary = YES;
    [self addChildBehavior:gb];
    [self addChildBehavior:cb];
}
return self;
</code></pre>

<p>}</p>

<p>@end
```</p>

<p>另一种比较高级一点，需要对计算完全定义。在默认的行为或者它们组合不能满足禽兽般的产品经理/设计师的需求是，亲爱的骚年..开始自己写吧..其实说简单也简单，UIDynamicBehavior里提供了一个<code>@property(nonatomic, copy) void (^action)(void)</code>，animator将在每次animation step（就是需要计算动画时）调用这个block。就是说，你可以通过设定这个block来实现自己的行为。基本思路就是在这个block中向所有item询问它们当前的center和transform状态，然后开始计算，然后把计算后的相应值再赋予item，从而改变在屏幕上的位置，大小，角度等。</p>

<h3>UIKit动力学的性能分析和限制</h3>

<p>使用物理引擎不是没有代价的的，特别是在碰撞检测这块，是要耗费一定CPU资源的。但是以测试的情况来看，如果只是UI层面上的碰撞检测还是没有什么问题的，我自己实测iPhone4上同时进行数十个碰撞计算完全没有掉帧的情况。因此如果只是把其用在UI特效上，应该不用太在意资源的耗费。但是如果同时有成百上千的碰撞需要处理的情况，可能会出现卡顿吧。</p>

<p>对于UIDynamicItem来说，当它们被添加到动画系统后，我们只能通过动画系统来改变位置，而外部的对于UIDynamicItem的center,transform等设定是被忽略的（其实这也是大多数2D引擎的实现策略，算不上限制）。</p>

<p>主要的限制是在当计算迭代无法得到有效解的时候，动画将无法正确呈现。这对于绝大多数物理引擎都是一样的。迭代不能收敛时整个物理系统处于不确定的状态，比如初始时就设定了碰撞物体位于边界内部，或者在狭小空间内放入了过多的非弹性碰撞物体等。另外，这个引擎仅仅只是用来呈现UI效果，它并没有保证物理上的精确度，因此如果要用它来做UI以外的事情，有可能是无法得到很好的结果的。</p>

<h3>总结</h3>

<p>总之就是一套全新的UI交互的视觉体验和效果，但是并非处处适用。在合适的地方使用可以增加体验，但是也会有其他方式更适合的情况。所以拉上你的设计师好基友去开拓新的大陆吧…</p>
]]></content>
  </entry>
  
</feed>
